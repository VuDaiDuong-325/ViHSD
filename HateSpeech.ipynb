{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"VIpw0Wu5by_v"},"outputs":[],"source":["# ======================================================\n","# CELL 1: K·∫æT N·ªêI GOOGLE DRIVE\n","# ======================================================\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xzjqR0QecCz5"},"outputs":[],"source":["# ======================================================\n","# CELL 2: C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N (FINAL STRUCTURE)\n","# ======================================================\n","import os\n","\n","# 1. Th∆∞ m·ª•c g·ªëc\n","BASE_PATH = \"/content/drive/MyDrive/Project_HateSpeech\"\n","\n","# 2. ƒê·ªãnh nghƒ©a c√°c th∆∞ m·ª•c con\n","DIR_DATA      = f\"{BASE_PATH}/dataset\"\n","DIR_KEYWORD   = f\"{BASE_PATH}/keyword\"\n","DIR_EMBEDDING = f\"{BASE_PATH}/Embedding&Model/embedding\"\n","DIR_MODEL     = f\"{BASE_PATH}/Embedding&Model/model\"\n","DIR_CONFIG    = f\"{BASE_PATH}/config\"\n","\n","# T·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c (n·∫øu ch∆∞a c√≥)\n","for path in [DIR_DATA, DIR_KEYWORD, DIR_EMBEDDING, DIR_MODEL, DIR_CONFIG]:\n","    os.makedirs(path, exist_ok=True)\n","\n","# 3. ƒê∆∞·ªùng d·∫´n chi ti·∫øt t·ªõi t·ª´ng file\n","# --- Nh√≥m D·ªØ li·ªáu ---\n","DATASET_FILE     = f\"{DIR_DATA}/dataset.csv\"\n","\n","# --- Nh√≥m T√†i nguy√™n ---\n","KEYWORDS_FILE    = f\"{DIR_KEYWORD}/keywords.json\"\n","WHITELIST_FILE   = f\"{DIR_KEYWORD}/whitelist.json\"\n","\n","# --- Nh√≥m Vector h√≥a ---\n","EMBEDDING_FILE   = f\"{DIR_EMBEDDING}/cc.vi.300.vec\"\n","\n","# --- Nh√≥m Model ---\n","MODEL_FILE       = f\"{DIR_MODEL}/hate_speech_model.keras\"\n","TOKENIZER_FILE   = f\"{DIR_MODEL}/tokenizer.pickle\"\n","\n","# --- Nh√≥m C·∫•u h√¨nh ---\n","NGROK_TOKEN_FILE = f\"{DIR_CONFIG}/ngrok_token.txt\"\n","\n","# 4. Tham s·ªë Model\n","MAX_WORDS = 20000\n","MAX_LEN   = 100\n","EMBED_DIM = 300\n","\n","print(f\"‚úÖ ƒê√£ c·∫≠p nh·∫≠t c·∫•u tr√∫c th∆∞ m·ª•c ho√†n ch·ªânh!\")\n","print(f\"üìÇ Dataset: {DIR_DATA}\")\n","print(f\"üìÇ Keyword:  {DIR_KEYWORD}\")\n","print(f\"üìÇ Embedding:  {DIR_EMBEDDING}\")\n","print(f\"üìÇ Model:  {DIR_MODEL}\")\n","print(f\"üìÇ Config:  {DIR_CONFIG}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJcSf6tEUiIY"},"outputs":[],"source":["import json\n","\n","# ======================================================\n","# CELL 3: T·∫†O FILE TEENCODE (JSON)\n","# ======================================================\n","teencode_dict = {\n","    \"ctrai\": \"con trai\",\n","    \"kh√¥g\": \"kh√¥ng\",\n","    \"cskh\": \"chƒÉm s√≥c kh√°ch h√†ng\",\n","    \"bme\": \"b·ªë m·∫π\",\n","    \"cta\": \"ch√∫ng ta\",\n","    \"mih\": \"m√¨nh\",\n","    \"mqh\": \"m·ªëi quan h·ªá\",\n","    \"cgai\": \"con g√°i\",\n","    \"nh·ªØg\": \"nh·ªØng\",\n","    \"mng\": \"m·ªçi ng∆∞·ªùi\",\n","    \"svtn\": \"sinh vi√™n t√¨nh nguy·ªán\",\n","    \"r\": \"r·ªìi\",\n","    \"th\": \"th√¥i\",\n","    \"p√°c\": \"b√°c\",\n","    \"qtam\": \"quan t√¢m\",\n","    \"th∆∞∆°g\": \"th∆∞∆°ng\",\n","    \"qt√¢m\": \"quan t√¢m\",\n","    \"chug\": \"chung\",\n","    \"tr∆∞·ªùg\": \"tr∆∞·ªùng\",\n","    \"thoy\": \"th√¥i\",\n","    \"vailoz\": \"v√£i l·ªìn\",\n","    \"ƒëki\": \"ƒëƒÉng k√Ω\",\n","    \"clb\": \"c√¢u l·∫°c b·ªô\",\n","    \"app\": \"ph·∫ßn m·ªÅm\",\n","    \"√©o\": \"ƒë√©o\",\n","    \"db\": \"ƒë·∫ßu bu·ªìi\",\n","    \"atsm\": \"·∫£o t∆∞·ªüng s·ª©c m·∫°nh\",\n","    \"·∫°k\": \"·∫°\",\n","    \"dell\": \"ƒë√©o\",\n","    \"thg\": \"th·∫±ng\",\n","    \"nma\": \"nh∆∞ng m√†\",\n","    \"nhma\": \"nh∆∞ng m√†\",\n","    \"edit\": \"ch·ªânh s·ª≠a\",\n","    \"cv\": \"c√¥ng vi·ªác\",\n","    \"vch\": \"v√£i ch∆∞·ªüng\",\n","    \"c√πg\": \"c√πng\",\n","    \"pn\": \"b·∫°n\",\n","    \"z\": \"v·∫≠y\",\n","    \"v\": \"v·∫≠y\",\n","    \"zzz\": \"ng·ªß\",\n","    \"pjt\": \"bi·∫øt\",\n","    \"thjk\": \"th√≠ch\",\n","    \"keke\": \"c∆∞·ªùi\",\n","    \"ktra\": \"ki·ªÉm tra\",\n","    \"ktx\": \"k√Ω t√∫c x√°\",\n","    \"nek\": \"n√®\",\n","    \"cg√°i\": \"con g√°i\",\n","    \"nthe\": \"nh∆∞ th·∫ø\",\n","    \"ch√∫g\": \"ch√∫ng\",\n","    \"k√°i\": \"c√°i\",\n","    \"t√¨h\": \"t√¨nh\",\n","    \"ph√≤g\": \"ph√≤ng\",\n","    \"l√≤g\": \"l√≤ng\",\n","    \"t·ª´g\": \"t·ª´ng\",\n","    \"r·∫±g\": \"r·∫±ng\",\n","    \"s·ªëg\": \"s·ªëng\",\n","    \"thuj\": \"th√¥i\",\n","    \"thu∆°ng\": \"th∆∞∆°ng\",\n","    \"c√†g\": \"c√†ng\",\n","    \"ƒëky\": \"ƒëƒÉng k√Ω\",\n","    \"b·∫±g\": \"b·∫±ng\",\n","    \"svi√™n\": \"sinh vi√™n\",\n","    \"viral\": \"n·ªïi ti·∫øng\",\n","    \"mxh\": \"m·∫°ng x√£ h·ªôi\",\n","    \"√°k\": \"√°\",\n","    \"mm\": \"m·∫π m√†y\",\n","    \"ƒë√°g\": \"ƒë√°ng\",\n","    \"nvay\": \"nh∆∞ v·∫≠y\",\n","    \"nhjeu\": \"nhi·ªÅu\",\n","    \"xg\": \"xu·ªëng\",\n","    \"z·ªìi\": \"r·ªìi\",\n","    \"trag\": \"trang\",\n","    \"z·ªØ\": \"d·ªØ\",\n","    \"atrai\": \"anh trai\",\n","    \"kte\": \"kinh t·∫ø\",\n","    \"ƒë·ªôg\": \"ƒë·ªông\",\n","    \"lmht\": \"li√™n minh huy·ªÅn tho·∫°i\",\n","    \"g·∫Øg\": \"g·∫Øng\",\n","    \"ƒëzai\": \"ƒë·∫πp trai\",\n","    \"thgian\": \"th·ªùi gian\",\n","    \"plz\": \"l√†m ∆°n\",\n","    \"ƒë·ªìg\": \"ƒë·ªìng\",\n","    \"btrai\": \"b·∫°n trai\",\n","    \"nth√™\": \"nh∆∞ th·∫ø\",\n","    \"vl\": \"v√£i l·ªìn\",\n","    \"h√¨h√¨\": \"c∆∞·ªùi\",\n","    \"v·ªçg\": \"v·ªçng\",\n","    \"hihe\": \"c∆∞·ªùi\",\n","    \"ƒë√¥g\": \"ƒë√¥ng\",\n","    \"rƒÉg\": \"rƒÉng\",\n","    \"th∆∞·ªùg\": \"th∆∞·ªùng\",\n","    \"tc·∫£m\": \"t√¨nh c·∫£m\",\n","    \"ƒë·ª©g\": \"ƒë·ª©ng\",\n","    \"ksao\": \"kh√¥ng sao\",\n","    \"dz\": \"ƒë·∫πp trai\",\n","    \"hjxhjx\": \"hix hix\",\n","    \"cm√†y\": \"ch√∫ng m√†y\",\n","    \"xu·ªëg\": \"xu·ªëng\",\n","    \"nk∆∞\": \"nh∆∞\",\n","    \"lquan\": \"li√™n quan\",\n","    \"lqmb\": \"li√™n qu√¢n mobile\",\n","    \"mlbb\": \"mobile legend bang bang\",\n","    \"ti·∫øg\": \"ti·∫øng\",\n","    \"hajz\": \"haizz\",\n","    \"ƒëb\": \"ƒë·∫ßu bu·ªìi\",\n","    \"cjv\": \"c√°i g√¨ v·∫≠y\",\n","    \"ccjv\": \"con c·∫∑c g√¨ v·∫≠y\",\n","    \"xih\": \"xinh\",\n","    \"h√¨h\": \"h√¨nh\",\n","    \"th√†h\": \"th√†nh\",\n","    \"ngke\": \"nghe\",\n","    \"dz·∫≠y\": \"d·∫≠y\",\n","    \"teencode\": \"tin c·ªët\",\n","    \"tn√†o\": \"th·∫ø n√†o\",\n","    \"t∆∞·ªüg\": \"t∆∞·ªüng\",\n","    \"ctrinh\": \"ch∆∞∆°ng tr√¨nh\",\n","    \"phog\": \"phong\",\n","    \"h√¥g\": \"kh√¥ng\",\n","    \"z√¨a\": \"g√¨\",\n","    \"k≈©g\": \"c≈©ng\",\n","    \"ntnao\": \"nh∆∞ th·∫ø n√†o\",\n","    \"tr·ªçg\": \"tr·ªçng\",\n","    \"nth·∫ø\": \"nh∆∞ th·∫ø\",\n","    \"nƒÉg\": \"nƒÉng\",\n","    \"ngƒë√≥\": \"ng∆∞·ªùi ƒë√≥\",\n","    \"lquen\": \"l√†m quen\",\n","    \"ri√™g\": \"ri√™ng\",\n","    \"ngag\": \"ngang\",\n","    \"h√™h√™\": \"c∆∞·ªùi\",\n","    \"h·ªâu\": \"hi·ªÉu\",\n","    \"bnhiu\": \"bao nhi√™u\",\n","    \"ng·ªëk\": \"ng·ªëc\",\n","    \"k·∫≠u\": \"c·∫≠u\",\n","    \"highland\": \"qu√°n c√† ph√™\",\n","    \"hlv\": \"hu·∫•n luy·ªán vi√™n\",\n","    \"kqua\": \"k·∫øt qu·∫£\",\n","    \"htrc\": \"h√¥m tr∆∞·ªõc\",\n","    \"ƒë·ªãh\": \"ƒë·ªãnh\",\n","    \"gƒë√¨nh\": \"gia ƒë√¨nh\",\n","    \"gi·ªëg\": \"gi·ªëng\",\n","    \"cs·ªëng\": \"cu·ªôc s·ªëng\",\n","    \"cuti\": \"d·ªÖ th∆∞∆°ng\",\n","    \"cute\": \"d·ªÖ th∆∞∆°ng\",\n","    \"xug\": \"xung\",\n","    \"z√πi\": \"r·ªìi\",\n","    \"bnhi√™u\": \"bao nhi√™u\",\n","    \"cb·ªã\": \"chu·∫©n b·ªã\",\n","    \"k√≤n\": \"c√≤n\",\n","    \"bu√¥g\": \"bu√¥ng\",\n","    \"bulul\": \"b√∫ l·ªìn\",\n","    \"csong\": \"cu·ªôc s·ªëng\",\n","    \"solo\": \"m·ªôt m√¨nh\",\n","    \"1v1\": \"ƒë·ªëi ƒë·∫ßu\",\n","    \"1vs1\": \"ƒë·ªëi ƒë·∫ßu\",\n","    \"ch√†g\": \"ch√†ng\",\n","    \"chƒÉg\": \"chƒÉng\",\n","    \"ng√†h\": \"ng√†nh\",\n","    \"llac\": \"li√™n l·∫°c\",\n","    \"nk∆∞ng\": \"nh∆∞ng\", \"n·∫Øg\": \"n·∫Øng\", \"t√≠h\": \"t√≠nh\",\n","    \"kho·∫£g\": \"kho·∫£ng\", \"th√≠k\": \"th√≠ch\", \"ngƒëo\": \"ng∆∞·ªùi ƒë√≥\",\n","    \"ngkh√°c\": \"ng∆∞·ªùi kh√°c\", \"th·∫≥g\": \"th·∫≥ng\", \"k·∫£m\": \"c·∫£m\",\n","    \"d√†h\": \"d√†nh\", \"j√∫p\": \"gi√∫p\", \"l·∫∑g\": \"l·∫∑ng\",\n","    \"vƒë√™\": \"v·∫•n ƒë·ªÅ\", \"bb√®\": \"b·∫°n b√®\", \"b√≥g\": \"b√≥ng\",\n","    \"dky\": \"ƒëƒÉng k√Ω\", \"d√≤g\": \"d√≤ng\", \"u·ªëg\": \"u·ªëng\",\n","    \"ty√™u\": \"t√¨nh y√™u\", \"snvv\": \"sinh nh·∫≠t vui v·∫ª\", \"ƒëtho·∫°i\": \"ƒëi·ªán tho·∫°i\",\n","    \"qhe\": \"quan h·ªá\", \"cviec\": \"c√¥ng vi·ªác\", \"t∆∞·ª£g\": \"t∆∞·ª£ng\",\n","    \"q√†\": \"qu√†\", \"thjc\": \"th√≠ch\", \"nh∆∞q\": \"nh∆∞ng\",\n","    \"cƒë·ªùi\": \"cu·ªôc ƒë·ªùi\", \"bth∆∞·ªùng\": \"b√¨nh th∆∞·ªùng\", \"z√†\": \"gi√†\",\n","    \"ƒë√°h\": \"ƒë√°nh\", \"xloi\": \"xin l·ªói\", \"z√°m\": \"d√°m\",\n","    \"qtr·ªçng\": \"quan tr·ªçng\", \"b√¨h\": \"b√¨nh\", \"lzi\": \"l√†m g√¨\",\n","    \"qh·ªá\": \"quan h·ªá\", \"ƒëhbkhn\": \"ƒë·∫°i h·ªçc b√°ch khoa h√† n·ªôi\", \"hajzz\": \"haizz\",\n","    \"k·ªßa\": \"c·ªßa\", \"ƒëhkhtn\": \"ƒë·∫°i h·ªçc khoa h·ªçc t·ª± nhi√™n\",\n","    \"ƒëh\": \"ƒë·∫°i h·ªçc\", \"ƒë√≥g\": \"ƒë√≥ng\", \"cka\": \"cha\", \"m√∫n\": \"mu·ªën\",\n","    \"lgi\": \"l√†m g√¨\", \"nv·∫≠y\": \"nh∆∞ v·∫≠y\", \"q·∫£\": \"qu·∫£\",\n","    \"ƒëki·ªán\": \"ƒëi·ªÅu ki·ªán\", \"n√®k\": \"n√®\", \"tlai\": \"t∆∞∆°ng lai\",\n","    \"bsƒ©\": \"b√°c sƒ©\", \"hk√¨\": \"h·ªçc k·ª≥\", \"ƒëcsvn\": \"ƒë·∫£ng c·ªông s·∫£n vi·ªát nam\",\n","    \"vde\": \"v·∫•n ƒë·ªÅ\", \"chta\": \"ch√∫ng ta\", \"√≤y\": \"r·ªìi\",\n","    \"ltinh\": \"linh tinh\", \"ngyeu\": \"ng∆∞·ªùi y√™u\", \"ƒëthoai\": \"ƒëi·ªán tho·∫°i\",\n","    \"snghƒ©\": \"suy nghƒ©\", \"n·∫∑g\": \"n·∫∑ng\", \"h·ªçk\": \"h·ªçc\",\n","    \"d·ª´g\": \"d·ª´ng\", \"hph√∫c\": \"h·∫°nh ph√∫c\", \"hiha\": \"c∆∞·ªùi\",\n","    \"wt√¢m\": \"quan t√¢m\", \"th√≠ck\": \"th√≠ch\", \"chu·ªán\": \"chuy·ªán\",\n","    \"l·∫°h\": \"l·∫°nh\", \"f√¢y\": \"facebook\", \"ntn√†y\": \"nh∆∞ th·∫ø n√†y\",\n","    \"l√∫k\": \"l√∫c\", \"haj\": \"hai\", \"ng√≠a\": \"ngh√≠a\",\n","    \"m·ªõj\": \"m·ªõi\", \"hs∆°\": \"h·ªì s∆°\", \"ctraj\": \"con trai\",\n","    \"trg\": \"tr∆∞·ªùng\", \"ny√™u\": \"ng∆∞·ªùi y√™u\", \"ƒëiiiiiii\": \"ƒëi\",\n","    \"r·ªìii\": \"r·ªìi\", \"cj\": \"ch·ªã\", \"c\": \"c·∫∑c\",\n","    \"kih\": \"kinh\", \"kb\": \"k·∫øt b·∫°n\", \"hixxx\": \"hix\",\n","    \"dth∆∞∆°ng\": \"d·ªÖ th∆∞∆°ng\", \"nhi·ªÅuuu\": \"nhi·ªÅu\", \"ctr√¨nh\": \"ch∆∞∆°ng tr√¨nh\",\n","    \"m√¨nk\": \"m√¨nh\", \"mjh\": \"m√¨nh\", \"ng\": \"ng∆∞·ªùi\",\n","    \"vc\": \"v·ª£ ch·ªìng\", \"uhm\": \"·ª´m\", \"th·ª≥\": \"th√¨\",\n","    \"nyc\": \"ng∆∞·ªùi y√™u c≈©\", \"tks\": \"c·∫£m ∆°n\", \"n√†g\": \"n√†ng\",\n","    \"th√¥ii\": \"th√¥i\", \"ƒëj√™n\": \"ƒëi√™n\", \"bg√°i\": \"b·∫°n g√°i\",\n","    \"v·ªõii\": \"v·ªõi\", \"xink\": \"xinh\", \"hƒë·ªông\": \"h√†nh ƒë·ªông\",\n","    \"ƒëh·ªçc\": \"ƒë·∫°i h·ªçc\", \"mk\": \"m√¨nh\", \"bn\": \"b·∫°n\",\n","    \"thik\": \"th√≠ch\", \"mn\": \"m·ªçi ng∆∞·ªùi\", \"nguoi\": \"ng∆∞·ªùi\",\n","    \"n√≥gn\": \"n√≥ng\", \"hok\": \"kh√¥ng\", \"ko\": \"kh√¥ng\",\n","    \"bik\": \"bi·∫øt\", \"vs\": \"v·ªõi\", \"cx\": \"c≈©ng\",\n","    \"mik\": \"m√¨nh\", \"wtf\": \"c√°i qu√°i g√¨\", \"ƒëc\": \"ƒë∆∞·ª£c\",\n","    \"cmt\": \"b√¨nh lu·∫≠n\", \"ck\": \"ch·ªìng\", \"chk\": \"ch·ªìng\",\n","    \"ngta\": \"ng∆∞·ªùi ta\", \"gƒë\": \"gia ƒë√¨nh\", \"oh\": \"·ªì\",\n","    \"vk\": \"v·ª£\", \"ct√°c\": \"c√¥ng t√°c\", \"sg\": \"s√†i g√≤n\",\n","    \"ae\": \"anh em\", \"ah\": \"√†\", \"·∫°h\": \"·∫°\",\n","    \"r√¨\": \"g√¨\", \"ms\": \"m·ªõi\", \"vn\": \"vi·ªát nam\",\n","    \"nhaa\": \"nha\", \"c≈©g\": \"c≈©ng\", \"ƒëag\": \"ƒëang\",\n","    \"∆°iii\": \"∆°i\", \"hic\": \"hix\", \"ace\": \"anh ch·ªã em\",\n","    \"√†k\": \"√†\", \"uh\": \"·ª´\", \"cmm\": \"con m·∫π m√†y\",\n","    \"cmnr\": \"con m·∫π n√≥ r·ªìi\", \"∆°iiii\": \"∆°i\", \"hnay\": \"h√¥m nay\",\n","    \"ukm\": \"·ª´m\", \"tq\": \"trung qu·ªëc\", \"ctr\": \"ch∆∞∆°ng tr√¨nh\",\n","    \"ƒëii\": \"ƒëi\", \"nch\": \"n√≥i chuy·ªán\", \"trieu\": \"tri·ªáu\",\n","    \"hahah\": \"c∆∞·ªùi\", \"nta\": \"ng∆∞·ªùi ta\", \"ng√®o\": \"ngh√®o\",\n","    \"k√™h\": \"k√™nh\", \"ak\": \"√†\", \"ad\": \"admin\",\n","    \"dme\": \"ƒë·ªãt m·∫π\", \"djt\": \"ƒë·ªãt\", \"add fr\": \"th√™m b·∫°n\",\n","    \"j\": \"g√¨\", \"ny\": \"ng∆∞·ªùi y√™u\", \"dc\": \"ƒë∆∞·ª£c\",\n","    \"qc\": \"qu·∫£ng c√°o\", \"baoh\": \"bao gi·ªù\", \"zui\": \"vui\",\n","    \"z·∫ª\": \"v·∫ª\", \"tym\": \"tim\", \"aye\": \"anh y√™u em\",\n","    \"eya\": \"em y√™u anh\", \"fb\": \"facebook\", \"insta\": \"instagram\",\n","    \"z\": \"v·∫≠y\", \"thich\": \"th√≠ch\", \"vcl\": \"v√£i c·∫£ l·ªìn\",\n","    \"ƒët\": \"ƒëi·ªán tho·∫°i\", \"acc\": \"t√†i kho·∫£n\", \"ccho\": \"con ch√≥\",\n","    \"choei\": \"ch∆°i\", \"l\": \"l·ªìn\", \"loz\": \"l·ªìn\",\n","    \"lozz\": \"l·ªìn\", \"trc\": \"tr∆∞·ªõc\", \"chs\": \"ch·∫≥ng hi·ªÉu sao\",\n","    \"ƒëhs\": \"ƒë√©o hi·ªÉu sao\", \"q√°\": \"qu√°\", \"ntn\": \"nh∆∞ th·∫ø n√†o\",\n","    \"w√°\": \"qu√°\", \"z·∫≠y\": \"v·∫≠y\", \"z√¥\": \"v√¥\",\n","    \"ytb\": \"youtube\", \"vƒë\": \"v√£i ƒë√°i\", \"vchg\": \"v√£i ch∆∞·ªüng\",\n","    \"sml\": \"s·∫•p m·∫∑t l·ªù\", \"mlem\": \"ngon\", \"xl\": \"xin l·ªói\",\n","    \"cmn\": \"con m·∫π n√≥\", \"face\": \"facebook\", \"hjhj\": \"c∆∞·ªùi\",\n","    \"vv\": \"vui v·∫ª\", \"ns\": \"n√≥i\", \"iu\": \"y√™u\",\n","    \"vcƒë\": \"v√£i c·∫£ ƒë√°i\", \"in4\": \"th√¥ng tin\", \"qq\": \"qu·∫ßn qu√®\",\n","    \"sub\": \"theo d√µi\", \"kh\": \"kh√¥ng\", \"z·∫°\": \"v·∫≠y\",\n","    \"oy\": \"r·ªìi\", \"jo\": \"gi·ªù\", \"clmm\": \"c√°i l·ªìn m·∫π m√†y\",\n","    \"clgt\": \"c√°i l·ªìn g√¨ th·∫ø\", \"bsvv\": \"bu·ªïi s√°ng vui v·∫ª\",\n","    \"troai\": \"trai\", \"wa\": \"qu√°\", \"hjx\": \"hix\",\n","    \"e\": \"em\", \"ik\": \"ƒëi\", \"ji\": \"g√¨\",\n","    \"ce\": \"ch·ªã em\", \"lm\": \"l√†m\", \"ƒëz\": \"ƒë·∫πp trai\",\n","    \"sr\": \"xin l·ªói\", \"ib\": \"inbox\", \"hoy\": \"th√¥i\",\n","    \"ƒëbh\": \"ƒë√©o bao gi·ªù\", \"k\": \"kh√¥ng\", \"vd\": \"v√≠ d·ª•\",\n","    \"a\": \"anh\", \"c≈©ng z\": \"c≈©ng v·∫≠y\", \"z l√†\": \"v·∫≠y l√†\",\n","    \"unf\": \"h·ªßy k·∫øt b·∫°n\", \"my fen\": \"b·∫°n t√¥i\", \"fen\": \"b·∫°n\",\n","    \"cty\": \"c√¥ng ty\", \"on lai\": \"online\", \"u hai ba\": \"u23\",\n","    \"ai √¥ si ma\": \"h√†i\", \"k√¥\": \"kh√¥ng\", \"ƒëtqg\": \"ƒë·ªôi tuy·ªÉn qu·ªëc gia\",\n","    \"hqua\": \"h√¥m qua\", \"xog\": \"xong\", \"uk\": \"·ª´\",\n","    \"nho√©\": \"nh√©\", \"biet\": \"bi·∫øt\", \"qu√≠\": \"qu√Ω\",\n","    \"stk\": \"s·ªë t√†i kho·∫£n\", \"hong kong\": \"h·ªìng k√¥ng\", \"ƒë∆∞∆°c\": \"ƒë∆∞·ª£c\",\n","    \"ngh√†nh\": \"ng√†nh\", \"nvqs\": \"nghƒ©a v·ª• qu√¢n s·ª±\", \"ng·ª´oi\": \"ng∆∞·ªùi\",\n","    \"trog\": \"trong\", \"tgian\": \"th·ªùi gian\", \"bi√™t\": \"bi·∫øt\",\n","    \"f·∫£i\": \"ph·∫£i\", \"ngu·ªùi\": \"ng∆∞·ªùi\", \"tƒën\": \"th·∫ø ƒë√©o n√†o\",\n","    \"bth\": \"b√¨nh th∆∞·ªùng\", \"tgdd\": \"th·∫ø gi·ªõi di ƒë·ªông\", \"khg\": \"kh√¥ng\",\n","    \"nh∆∞g\": \"nh∆∞ng\", \"thpt\": \"trung h·ªçc ph·ªï th√¥ng\", \"th·∫±g\": \"th·∫±ng\",\n","    \"ƒëu·ª£c\": \"ƒë∆∞·ª£c\", \"dcu\": \"ƒë·ªãt c·ª•\", \"√†h\": \"√†\",\n","    \"ku\": \"cu\", \"th√Ωm\": \"th√≠m\", \"onl\": \"online\",\n","    \"z√¥\": \"d√¥\", \"z√∫\": \"v√∫\", \"cmnd\": \"ch·ª©ng minh nh√¢n d√¢n\",\n","    \"sƒët\": \"s·ªë ƒëi·ªán tho·∫°i\", \"klq\": \"kh√¥ng li√™n quan\", \"ok\": \"ƒë∆∞·ª£c\",\n","    \"m\": \"m√†y\", \"view\": \"c·∫£nh\", \"now\": \"b√¢y gi·ªù\", \"ngok\": \"ng·ªëc\",\n","    \"set\": \"ƒë·∫∑t\", \"nv\": \"nh√¢n vi√™n\", \"cheese\": \"ph√¥ mai\",\n","    \"t\": \"tao\", \"size\": \"k√≠ch th∆∞·ªõc\", \"decor\": \"trang tr√≠\",\n","    \"nc\": \"n∆∞·ªõc\", \"free\": \"mi·ªÖn ph√≠\", \"h\": \"gi·ªù\",\n","    \"thui\": \"th√¥i\", \"hn\": \"h√† n·ªôi\", \"socola\": \"s√¥ c√¥ la\",\n","    \"bt\": \"b√¨nh th∆∞·ªùng\", \"oke\": \"ƒë∆∞·ª£c\", \"nhg\": \"nh∆∞ng\",\n","    \"recommend\": \"g·ª£i √Ω\", \"shipper\": \"giao h√†ng\", \"best\": \"t·ªët\",\n","    \"check\": \"ki·ªÉm tra\", \"hot\": \"n·ªïi b·∫≠t\", \"full\": \"ƒë·∫ßy\",\n","    \"sale\": \"gi·∫£m gi√°\", \"mix\": \"k·∫øt h·ª£p\", \"ord\": \"ƒë·∫∑t h√†ng\",\n","    \"tui\": \"t√¥i\", \"voucher\": \"m√£ gi·∫£m gi√°\", \"th·ª© n\": \"th·ª© nhi·ªÅu\",\n","    \"note\": \"ghi ch√∫\", \"nice\": \"t·ªët\", \"ƒë\": \"ƒë√©o\",\n","    \"nchung\": \"n√≥i chung\", \"vote\": \"ƒë√°nh gi√°\", \"ncl\": \"n√≥i chung l√†\",\n","    \"good\": \"t·ªët\", \"nh\": \"nh∆∞ng\", \"b\": \"b·∫°n\",\n","    \"nvien\": \"nh√¢n vi√™n\", \"up\": \"ƒëƒÉng\", \"bill\": \"h√≥a ƒë∆°n\",\n","    \"bltm\": \"b√¥ng lan tr·ª©ng mu·ªëi\", \"fact\": \"s·ª± th·∫≠t\", \"cf\": \"c√† ph√™\",\n","    \"l√¥n`\": \"l·ªìn\", \"bthg\": \"b√¨nh th∆∞·ªùng\", \"to·∫πt\": \"tuy·ªát\",\n","    \"thk\": \"th√≠ch\", \"dag\": \"ƒëang\", \"delete\": \"x√≥a\",\n","    \"ss\": \"samsung\", \"xau\": \"x·∫•u\", \"dep\": \"ƒë·∫πp\",\n","    \"ngoo\": \"ngu\"\n","}\n","\n","# 3. L∆∞u file\n","file_path = f\"{DIR_KEYWORD}/teencode.json\"\n","with open(file_path, 'w', encoding='utf-8') as f:\n","    # indent=4 gi√∫p format ƒë·∫πp (m·ªói d√≤ng 1 c·∫∑p)\n","    # ensure_ascii=False gi√∫p hi·ªÉn th·ªã ti·∫øng Vi·ªát kh√¥ng b·ªã l·ªói \\u...\n","    json.dump(teencode_dict, f, ensure_ascii=False, indent=4)\n","TEENCODE_FILE    = f\"{DIR_KEYWORD}/teencode.json\"\n","print(f\"‚úÖ ƒê√£ l∆∞u file teencode.json th√†nh c√¥ng t·∫°i: {file_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6rwKRC9donD"},"outputs":[],"source":["# ======================================================\n","# CELL 4: IMPORT TH∆Ø VI·ªÜN & KI·ªÇM TRA H·ªÜ TH·ªêNG\n","# ======================================================\n","!pip install pyngrok flask emoji requests\n","\n","# 1. C√°c th∆∞ vi·ªán x·ª≠ l√Ω d·ªØ li·ªáu c∆° b·∫£n\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import emoji\n","import pickle\n","import re\n","import requests\n","import joblib\n","\n","# 2. C√°c th∆∞ vi·ªán Deep Learning (TensorFlow/Keras)\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, SpatialDropout1D, GlobalMaxPooling1D, Dropout, Input\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n","from pyngrok import ngrok\n","from flask import Flask, request, render_template_string, jsonify, session, redirect, url_for\n","\n","# 3. C·∫•u h√¨nh giao di·ªán bi·ªÉu ƒë·ªì\n","sns.set(style=\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 6)\n","\n","# 4. Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa c√°c file quan tr·ªçng\n","# (S·ª≠ d·ª•ng c√°c bi·∫øn ƒë∆∞·ªùng d·∫´n ƒë√£ ƒë·ªãnh nghƒ©a ·ªü Cell 2)\n","print(f\"üìÇ ƒêang ki·ªÉm tra d·ªØ li·ªáu t·∫°i: {BASE_PATH}\")\n","\n","files_to_check = {\n","    \"Dataset CSV\": DATASET_FILE,\n","    \"Keywords JSON\": KEYWORDS_FILE,\n","    \"Teencode JSON\": TEENCODE_FILE,\n","    \"Embedding Vector\": EMBEDDING_FILE,\n","    \"Ngrok Token\": NGROK_TOKEN_FILE\n","}\n","\n","all_good = True\n","for name, path in files_to_check.items():\n","    if os.path.exists(path):\n","        print(f\"  ‚úÖ {name}: OK\")\n","    else:\n","        print(f\"  ‚ùå {name}: KH√îNG T√åM TH·∫§Y (ƒê∆∞·ªùng d·∫´n: {path})\")\n","        all_good = False\n","\n","if all_good:\n","    print(\"\\n=> T·∫•t c·∫£ file ƒë√£ s·∫µn s√†ng!\")\n","else:\n","    print(\"\\n=> ‚ö†Ô∏è C√≥ file b·ªã thi·∫øu, vui l√≤ng ki·ªÉm tra l·∫°i Google Drive.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNtDr4UueWwT"},"outputs":[],"source":["# ======================================================\n","# CELL 5: LOAD TEENCODE & H√ÄM L√ÄM S·∫†CH TEXT\n","# ======================================================\n","\n","# Load Teencode n·∫øu ch∆∞a c√≥ (ƒë·ªÅ ph√≤ng)\n","if 'TEENCODE_DICT' not in globals():\n","    try:\n","        with open(TEENCODE_FILE, 'r', encoding='utf-8') as f:\n","            TEENCODE_DICT = json.load(f)\n","    except:\n","        TEENCODE_DICT = {}\n","\n","# 2. T·ªëi ∆∞u Regex Teencode\n","sorted_teencode = sorted(TEENCODE_DICT.keys(), key=len, reverse=True)\n","teencode_pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, sorted_teencode)) + r')\\b')\n","\n","def replace_teencode_regex(text):\n","    return teencode_pattern.sub(lambda match: TEENCODE_DICT[match.group(0)], text)\n","\n","# 3. H√†m x·ª≠ l√Ω Icon k√Ω t·ª± -> TI·∫æNG VI·ªÜT\n","def convert_emoticons_to_vietnamese(text):\n","    # Nh√≥m c∆∞·ªùi: :), :)), =)), :D, =D, ^^, :v, =]], :], :>, :3\n","    # Chuy·ªÉn th√†nh t·ª´ \"vui\" ho·∫∑c \"c∆∞·ªùi\" ƒë·ªÉ model hi·ªÉu ng·ªØ c·∫£nh t√≠ch c·ª±c\n","    text = re.sub(r'[:=]\\s*[\\)\\]\\}D>3]+', ' vui ', text)\n","    text = re.sub(r'\\^\\^', ' vui ', text)\n","    text = re.sub(r'[:=]\\s*v\\b', ' vui ', text)\n","\n","    # Nh√≥m bu·ªìn: :(, :((, =((, :<, T_T, ;_;, :'(\n","    # Chuy·ªÉn th√†nh \"bu·ªìn\"\n","    text = re.sub(r'[:=]\\s*[\\(\\[\\{<]+', ' bu·ªìn ', text)\n","    text = re.sub(r'T_T|;_;', ' bu·ªìn ', text)\n","\n","    # Nh√≥m b·∫•t ng·ªù: :o, :O, 0_0 -> \"ng·∫°c_nhi√™n\"\n","    text = re.sub(r'[:=]\\s*[oO0]', ' ng·∫°c_nhi√™n ', text)\n","\n","    # Nh√≥m ch·ª≠i th·ªÅ / ng√≥n tay th·ªëi: _|_ , ./. -> \"ch·ª≠i\" (t√≠n hi·ªáu ti√™u c·ª±c m·∫°nh)\n","    text = re.sub(r'_\\|_', ' ch·ª≠i ', text)\n","\n","    return text\n","\n","# 4. H√†m d·ªãch Emoji ti·∫øng Anh -> TI·∫æNG VI·ªÜT\n","# V√¨ th∆∞ vi·ªán emoji ch·ªâ ra ti·∫øng Anh, ta map c√°c t·ª´ ph·ªï bi·∫øn v·ªÅ ti·∫øng Vi·ªát\n","def translate_emoji_english_to_vietnamese(text):\n","    # Map c√°c t·ª´ kh√≥a emoji ti·∫øng Anh ph·ªï bi·∫øn sang ti·∫øng Vi·ªát\n","    # Model Hate Speech c·∫ßn nh·∫•t l√† c√°c t·ª´ ti√™u c·ª±c\n","    replace_dict = {\n","        'pouting_face': 't·ª©c_gi·∫≠n',\n","        'angry_face': 't·ª©c_gi·∫≠n',\n","        'middle_finger': 'ch·ª≠i',\n","        'knife': 'dao',\n","        'bomb': 'bom',\n","        'smiling_face': 'vui',\n","        'grinning_face': 'c∆∞·ªùi',\n","        'crying_face': 'kh√≥c',\n","        'broken_heart': 'ƒëau_l√≤ng',\n","        'thumbs_down': 't·ªá',\n","        'thumbs_up': 't·ªët'\n","    }\n","\n","    # Thay th·∫ø nhanh\n","    for eng, vie in replace_dict.items():\n","        text = text.replace(eng, vie)\n","\n","    return text\n","\n","def clean_text(text):\n","    if not isinstance(text, str):\n","        return \"\"\n","\n","    text = text.lower()\n","\n","    text = text.replace('\\n', ' ').replace('\\r', ' ')\n","\n","    # B1. X·ª≠ l√Ω Icon k√Ω t·ª± (:)) -> vui)\n","    text = convert_emoticons_to_vietnamese(text)\n","\n","    # B2. X·ª≠ l√Ω Emoji Unicode (üò° -> :pouting_face:)\n","    text = emoji.demojize(text)\n","    # X√≥a d·∫•u : ·ªü 2 ƒë·∫ßu (vd: :pouting_face: -> pouting_face)\n","    text = text.replace(':', ' ')\n","\n","    # B3. D·ªãch Emoji ti·∫øng Anh sang ti·∫øng Vi·ªát (pouting_face -> t·ª©c_gi·∫≠n)\n","    text = translate_emoji_english_to_vietnamese(text)\n","\n","    # B4. Thay th·∫ø Teencode\n","    text = replace_teencode_regex(text)\n","\n","    # B5. X√≥a URL, Email\n","    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\S+@\\S+', '', text)\n","\n","    # B6. X√≥a k√Ω t·ª± ƒë·∫∑c bi·ªát (Gi·ªØ l·∫°i ch·ªØ c√°i TV v√† kho·∫£ng tr·∫Øng)\n","    text = re.sub(r'[^\\w\\s√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë]', ' ', text)\n","\n","    # B7. X√≥a kho·∫£ng tr·∫Øng th·ª´a v√† g·∫°ch d∆∞·ªõi (n·∫øu c√≤n s√≥t t·ª´ emoji)\n","    text = re.sub(r'_', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    return text"]},{"cell_type":"code","source":["# ======================================================\n","# CELL 6: T·∫¢I DANH S√ÅCH T·ª™ N√ìNG TI·∫æNG ANH (LDNOOBW)\n","# ======================================================\n","def load_english_bad_words():\n","    url = \"https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/en\"\n","    print(\"‚è≥ ƒêang t·∫£i danh s√°ch t·ª´ n√≥ng ti·∫øng Anh t·ª´ GitHub...\")\n","\n","    try:\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            # T√°ch d√≤ng, x√≥a kho·∫£ng tr·∫Øng th·ª´a v√† chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng\n","            bad_words = set(line.strip().lower() for line in response.text.splitlines() if line.strip())\n","            print(f\"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng: {len(bad_words)} t·ª´.\")\n","            return bad_words\n","        else:\n","            print(f\"‚ùå L·ªói t·∫£i d·ªØ li·ªáu: Status code {response.status_code}\")\n","            return set()\n","    except Exception as e:\n","        print(f\"‚ùå L·ªói k·∫øt n·ªëi m·∫°ng: {e}\")\n","        return set()\n","\n","# Bi·∫øn to√†n c·ª•c ch·ª©a danh s√°ch t·ª´ c·∫•m\n","ENG_BAD_WORDS = load_english_bad_words()"],"metadata":{"id":"cbclQjwaz6tS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 7: H√ÄM QU√âT T·ª™ N√ìNG TI·∫æNG ANH\n","# ======================================================\n","def scan_english_offensive(text):\n","    \"\"\"\n","    Ki·ªÉm tra xem vƒÉn b·∫£n c√≥ ch·ª©a t·ª´ n√≥ng ti·∫øng Anh kh√¥ng.\n","    Tr·∫£ v·ªÅ: (C√≥ vi ph·∫°m hay kh√¥ng?, Nh√£n, T·ª´ vi ph·∫°m)\n","    \"\"\"\n","    # Ki·ªÉm tra xem bi·∫øn ENG_BAD_WORDS ƒë√£ ƒë∆∞·ª£c load ·ªü Cell 6 ch∆∞a\n","    if not text or 'ENG_BAD_WORDS' not in globals() or not ENG_BAD_WORDS:\n","        return False, 0, None\n","\n","    # 1. Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng\n","    text_lower = text.lower()\n","\n","    # 2. D√πng Regex ƒë·ªÉ t√°ch t·ª´ ch√≠nh x√°c (lo·∫°i b·ªè d·∫•u c√¢u d√≠nh li·ªÅn)\n","    words_in_text = re.findall(r'\\b\\w+\\b', text_lower)\n","\n","    # 3. Qu√©t danh s√°ch\n","    for word in words_in_text:\n","        if word in ENG_BAD_WORDS:\n","            return True, 1, word\n","\n","    return False, 0, None"],"metadata":{"id":"SI846Ok9z9rL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SohCqiahVla"},"outputs":[],"source":["# ======================================================\n","# CELL 8: PH√ÇN T√çCH, TR·ª∞C QUAN H√ìA & NH·∫¨N X√âT\n","# ======================================================\n","\n","# 1. ƒê·ªçc d·ªØ li·ªáu\n","df = pd.read_csv(DATASET_FILE)\n","\n","# 2. X·ª≠ l√Ω s·ªë li·ªáu\n","df['word_count'] = df['free_text'].apply(lambda x: len(str(x).split()))\n","\n","# --- S·ª¨A ƒê·ªîI: CH·ªà L·∫§Y PH·∫¶N NGUY√äN (INT) ---\n","avg_length = int(df['word_count'].mean())\n","\n","# Map nh√£n v√† S·∫Øp x·∫øp\n","label_map = {0: '0 - Clean', 1: '1 - Offensive', 2: '2 - Hate'}\n","df['label_name'] = df['label_id'].map(label_map)\n","order_list = ['0 - Clean', '1 - Offensive', '2 - Hate']\n","\n","# ƒê·∫øm s·ªë l∆∞·ª£ng\n","label_counts = df['label_id'].value_counts().sort_index()\n","\n","# 3. LOGIC T·ª∞ ƒê·ªòNG NH·∫¨N X√âT\n","# --- C√¢n b·∫±ng d·ªØ li·ªáu ---\n","max_c = label_counts.max()\n","min_c = label_counts.min()\n","ratio = max_c / min_c if min_c > 0 else 0\n","\n","balance_comment = \"\"\n","if ratio < 1.5:\n","    balance_comment = \"‚úÖ D·ªØ li·ªáu KH√Å C√ÇN B·∫∞NG. T·ªët cho vi·ªác hu·∫•n luy·ªán.\"\n","elif ratio < 3:\n","    balance_comment = \"‚ö†Ô∏è D·ªØ li·ªáu H∆†I L·ªÜCH (Imbalanced). Model c√≥ th·ªÉ thi√™n v·ªã nh√£n nhi·ªÅu h∆°n.\"\n","else:\n","    balance_comment = \"‚ùå D·ªØ li·ªáu M·∫§T C√ÇN B·∫∞NG NGHI√äM TR·ªåNG. C·∫ßn c√¢n nh·∫Øc k·ªπ thu·∫≠t Oversampling.\"\n","\n","# --- ƒê·ªô d√†i c√¢u ---\n","len_comment = \"\"\n","if avg_length < 5:\n","    len_comment = \"C√¢u QU√Å NG·∫ÆN. C√≥ th·ªÉ thi·∫øu ng·ªØ c·∫£nh.\"\n","elif 5 <= avg_length <= 20:\n","    len_comment = \"‚úÖ ƒê·ªô d√†i PH√ô H·ª¢P v·ªõi ƒë·∫∑c th√π b√¨nh lu·∫≠n MXH.\"\n","else:\n","    len_comment = \"C√¢u KH√Å D√ÄI so v·ªõi b√¨nh lu·∫≠n th√¥ng th∆∞·ªùng.\"\n","\n","# 4. In th√¥ng tin\n","print(f\"üìä T·ªîNG QUAN DATASET:\")\n","print(f\"- T·ªïng s·ªë c√¢u: {len(df):,}\")\n","print(f\"- ƒê·ªô d√†i trung b√¨nh: ~{avg_length} t·ª´/c√¢u\") # ƒê√£ hi·ªÉn th·ªã s·ªë nguy√™n\n","print(\"-\" * 50)\n","print(f\"NH·∫¨N X√âT:\")\n","print(f\"1. {balance_comment}\")\n","print(f\"2. {len_comment}\")\n","print(\"-\" * 50)\n","\n","# 5. V·∫Ω bi·ªÉu ƒë·ªì\n","fig = plt.figure(figsize=(15, 10))\n","grid = plt.GridSpec(2, 2, wspace=0.3, hspace=0.3)\n","\n","# --- Bi·ªÉu ƒë·ªì 1: C·ªôt ---\n","ax1 = fig.add_subplot(grid[0, 0])\n","sns.countplot(x='label_name', hue='label_name', data=df, order=order_list, palette='viridis', legend=False, ax=ax1)\n","\n","ax1.set_title('S·ªë l∆∞·ª£ng c√¢u theo nh√£n')\n","ax1.set_xlabel('')\n","ax1.set_ylabel('S·ªë l∆∞·ª£ng')\n","for p in ax1.patches:\n","    if p.get_height() > 0:\n","        ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n","                     ha='center', va='bottom', fontsize=10, fontweight='bold')\n","\n","# --- Bi·ªÉu ƒë·ªì 2: Tr√≤n ---\n","ax2 = fig.add_subplot(grid[0, 1])\n","colors = sns.color_palette('viridis', 3)\n","ax2.pie(label_counts, labels=[label_map[i] for i in label_counts.index],\n","        autopct='%1.1f%%', startangle=140, colors=colors, explode=(0.05, 0.05, 0.05))\n","ax2.set_title('T·ª∑ l·ªá ph√¢n b·ªë (%)')\n","\n","# --- Bi·ªÉu ƒë·ªì 3: Histogram ---\n","ax3 = fig.add_subplot(grid[1, :])\n","sns.histplot(df['word_count'], bins=50, kde=True, color='royalblue', ax=ax3)\n","ax3.axvline(avg_length, color='red', linestyle='dashed', linewidth=2, label=f'TB: ~{avg_length} t·ª´')\n","ax3.set_title('Ph√¢n b·ªë ƒë·ªô d√†i c√¢u')\n","ax3.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nEoMn_szhbVU"},"outputs":[],"source":["# ======================================================\n","# CELL 9: PREPROCESSING & SPLIT DATA\n","# ======================================================\n","\n","# 1. √Åp d·ª•ng l√†m s·∫°ch d·ªØ li·ªáu\n","df['clean_text'] = df['free_text'].apply(lambda x: clean_text(str(x)))\n","\n","# 2. Tokenizer\n","tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ')\n","tokenizer.fit_on_texts(df['clean_text']) # Fit tr√™n c·ªôt ƒë√£ l√†m s·∫°ch\n","word_index = tokenizer.word_index\n","print(f\"   => T√¨m th·∫•y {len(word_index)} t·ª´ ƒë·ªôc nh·∫•t trong t·ª´ ƒëi·ªÉn.\")\n","\n","# 3. Chuy·ªÉn vƒÉn b·∫£n sang chu·ªói s·ªë (Sequence) & Padding\n","X = tokenizer.texts_to_sequences(df['clean_text'])\n","X = pad_sequences(X, maxlen=MAX_LEN)\n","\n","# 4. Label Encoding (One-hot)\n","y = to_categorical(df['label_id'])\n","\n","# 5. Chia t·∫≠p Train/Test (80% Train - 20% Test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"‚úÖ D·ªØ li·ªáu s·∫µn s√†ng!\")\n","print(f\"   - Shape X_train: {X_train.shape}\")\n","print(f\"   - Shape y_train: {y_train.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PvQCtL4Dtxs"},"outputs":[],"source":["# ======================================================\n","# CELL 10: LOAD PRE-TRAINED EMBEDDING\n","# ======================================================\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_matrix = np.zeros((vocab_size, EMBED_DIM))\n","hit = 0\n","miss = 0\n","\n","print(f\"üîÑ ƒêang load vector t·ª´ {EMBEDDING_FILE}...\")\n","\n","try:\n","    with open(EMBEDDING_FILE, 'r', encoding='utf-8', errors='ignore') as f:\n","        # B·ªè qua d√≤ng ƒë·∫ßu ti√™n (ch·ª©a info file) n·∫øu c·∫ßn thi·∫øt\n","        first_line = f.readline()\n","\n","        # N·∫øu d√≤ng ƒë·∫ßu ch·ª©a s·ªë l∆∞·ª£ng vector (th∆∞·ªùng ng·∫Øn), ta b·ªè qua.\n","        # N·∫øu d√≤ng ƒë·∫ßu l√† vector lu√¥n (d√†i), ta quay l·∫°i.\n","        if len(first_line.split()) > 2:\n","            f.seek(0)\n","\n","        for line in f:\n","            values = line.rstrip().rsplit(' ')\n","            word = values[0]\n","\n","            # --- KI·ªÇM TRA AN TO√ÄN ---\n","            # Ch·ªâ l·∫•y d√≤ng n√†o ƒë·ªß 300 chi·ªÅu + 1 t·ª´ = 301 ph·∫ßn t·ª≠\n","            if len(values) != EMBED_DIM + 1:\n","                continue\n","\n","            if word in tokenizer.word_index:\n","                try:\n","                    idx = tokenizer.word_index[word]\n","                    coefs = np.asarray(values[1:], dtype='float32')\n","                    embedding_matrix[idx] = coefs\n","                    hit += 1\n","                except ValueError:\n","                    continue\n","\n","    print(f\"‚úÖ Ho√†n t·∫•t! T√¨m th·∫•y {hit} t·ª´, kh√¥ng th·∫•y {vocab_size - hit} t·ª´.\")\n","\n","except FileNotFoundError:\n","    print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file embedding. H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iljuWbnjDxDd"},"outputs":[],"source":["# ======================================================\n","# CELL 11: BUILD MODEL, TRAIN & SAVE\n","# ======================================================\n","\n","# 1. ƒê·ªãnh nghƒ©a Model\n","model = Sequential()\n","model.add(Input(shape=(MAX_LEN,)))\n","\n","model.add(Embedding(vocab_size, EMBED_DIM, weights=[embedding_matrix], trainable=False))\n","model.add(SpatialDropout1D(0.3))\n","\n","model.add(Bidirectional(LSTM(64, return_sequences=True)))\n","model.add(GlobalMaxPooling1D())\n","\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(3, activation='softmax'))\n","\n","# 2. Compile\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n","model.summary()\n","\n","# 3. Callbacks\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_loss', save_best_only=True)\n","\n","# 4. Train\n","print(\"\\nüöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán...\")\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=20,\n","    batch_size=32,\n","    validation_data=(X_test, y_test),\n","    callbacks=[early_stop, checkpoint],\n","    verbose=1 # verbose=1: Hi·ªán thanh ti·∫øn tr√¨nh (progress bar)\n",")\n","\n","# 5. L∆∞u Tokenizer (Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·ª± ƒë·ªông b·ªüi checkpoint)\n","with open(TOKENIZER_FILE, 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","print(f\"\\n‚úÖ ƒê√£ l∆∞u Model t·∫°i: {MODEL_FILE}\")\n","print(f\"‚úÖ ƒê√£ l∆∞u Tokenizer t·∫°i: {TOKENIZER_FILE}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmuSrhEVnCx0"},"outputs":[],"source":["# ======================================================\n","# CELL 12: C·∫¨P NH·∫¨T FILE KEYWORDS.JSON\n","# ======================================================\n","valid_keywords = {\n","  \"Ph√¢n bi·ªát v√πng mi·ªÅn\": [\n","    \"b·∫Øc k·ª≥\", \"nam k·ª≥\", \"trung k·ª≥\", \"parky\", \"namiki\", \"hoa thanh que\", \"nh√† qu√™\", \"t·ªôc\", \"m·ªçi mi√™n\", \"bake\", \"narke\"\n","  ],\n","  \"Ch√≠nh tr·ªã / Nh·∫°y c·∫£m\": [\n","    \"ph·∫£n ƒë·ªông\", \"c·ªông s·∫£n\", \"ch·∫ø ƒë·ªô\", \"ƒëu c√†ng\", \"ba que\", \"tham nh≈©ng\", \"d√¢n ch·ªß cu·ªôi\", \"b√≤ ƒë·ªè\", \"c√°ch m·∫°ng m√†u\"\n","  ],\n","  \"K√≠ch ƒë·ªông / B·∫°o l·ª±c\": [\n","     \"b·∫Øn b·ªè\", \"gi·∫øt\", \"ch√©m\", \"t·ª≠ h√¨nh\", \"ƒë√°nh ch·∫øt\", \"th·ªß ti√™u\", \"x·ª≠ b·∫Øn\", \"treo c·ªï\", \"bƒÉm v·∫±m\", \"thanh tr·ª´ng\"\n","  ],\n","  \"C·ªï x√∫y / X√∫i gi·ª•c\": {\n","    \"T·ª´ kh√≥a c·ªë ƒë·ªãnh\": [\n","        \"t·ª± t·ª≠ ƒëi\", \"t·ª± s√°t ƒëi\", \"nh·∫£y c·∫ßu ƒëi\", \"nh·∫£y l·∫ßu ƒëi\", \"reset ki·∫øp sau\"\n","    ],\n","    \"Bi·∫øn th·ªÉ Regex (Ng·∫Øn g·ªçn)\": [\n","        r\"(m√†y|m|b·∫°n|con|th·∫±ng|n√≥)[ ]*ch·∫øt[ ]*(ƒëi|ƒë√™|li·ªÅn|ngay)\",\n","        r\"ch·∫øt[ ]*(ƒëi|ƒë√™|li·ªÅn|ngay|lu√¥n)\",\n","        r\"reset[ ]*(game|server)[ ]*ƒëi\"\n","    ]\n","  },\n","  \"X√∫c ph·∫°m / T·ª•c tƒ©u\": {\n","    \"T·ª´ kh√≥a c·ªë ƒë·ªãnh\": [\n","      \"ngu\", \"√≥c ch√≥\", \"ƒë·ªì ch√≥\", \"ch√≥ ƒë·∫ª\", \"ch√≥ ch·∫øt\",\n","      \"s√∫c v·∫≠t\", \"c√∫t x√©o\", \"m·∫π m√†y\", \"c·∫∑c\", \"l·ªìn\", \"ƒë√©o\", \"ƒë·ª•\",\n","      \"bu·ªìi\", \"cak\", \"kak\", \"ƒëƒ©\", \"ƒëi·∫øm\", \"ph√≤\", \"bitch\", \"cave\",\n","      \"dcmm\", \"ƒëcmm\", \"vcl\"\n","    ],\n","    \"Bi·∫øn th·ªÉ Regex (Ng·∫Øn g·ªçn)\": [\n","      r\"\\bv[.,\\s]*l\\b\",                       # vl\n","      r\"\\bc[.,\\s]*m[.,\\s]*(m|n)\\b\",           # cmm\n","      r\"\\b(ƒë|d)[.,\\s]*(c|k)?[.,\\s]*m+\\b\",     # dcm\n","      r\"\\bv[.,\\s]*(l|c|k)+\\b\",                # vcl\n","      r\"\\b(c)?[.,\\s]*m[.,\\s]*m[.,\\s]*b\\b\",    # cmmb\n","      r\"\\bb[.,\\s]*m[.,\\s]*g\\b\",               # bmg\n","      r\"(ƒë|d)[.,\\s]*√©[.,\\s]*o\",               # ƒë√©o\n","      r\"c[.,\\s]*·∫∑[.,\\s]*c\"                    # c·∫∑c\n","    ]\n","  },\n","  \"Mi·ªát th·ªã ngo·∫°i h√¨nh (Body Shaming)\": [\n","      \"b√©o nh∆∞ l·ª£n\", \"m·∫≠p nh∆∞ heo\", \"con heo m·∫≠p\", \"x·∫•u ƒëau x·∫•u ƒë·ªõn\",\n","      \"m·∫∑t l·ªìn\", \"m√†n h√¨nh ph·∫≥ng\", \"hai l∆∞ng\"\n","  ],\n","  \"Ph√¢n bi·ªát gi·ªõi t√≠nh\": [\n","      \"ƒë·ªì ƒë√†n b√†\", \"√≥c ƒë√†n b√†\", \"t√≠nh ƒë√†n b√†\", \"th·ª© ƒë√†n b√†\", \"m·∫•y con d·∫©m\",\n","      \"v·ªÅ r·ª≠a b√°t\", \"v·ªÅ h·∫ßu ch·ªìng\", \"m√°y ƒë·∫ª\"\n","  ],\n","  \"Ph√¢n bi·ªát t√¥n gi√°o\": [\n","      \"th·ª£ tu\", \"s∆∞ h·ªï mang\", \"t√† ƒë·∫°o\", \"bu√¥n th·∫ßn b√°n th√°nh\", \"con chi√™n gh·∫ª\"\n","  ]\n","}\n","\n","positive_keywords = [\n","    \"ƒë√°ng y√™u\", \"d·ªÖ th∆∞∆°ng\", \"xinh g√°i\", \"ƒë·∫πp trai\", \"ngoan\",\n","    \"t·ªët b·ª•ng\", \"hi·ªÅn l√†nh\", \"tuy·ªát v·ªùi\", \"xu·∫•t s·∫Øc\", \"th√¥ng minh\",\n","    \"y√™u th·∫ø\", \"c∆∞ng x·ªâu\", \"c∆∞ng th·∫ø\", \"gi·ªèi qu√°\", \"th∆∞∆°ng l·∫Øm\",\n","    \"xinh th·∫ø\", \"ƒë·∫πp th·∫ø\", \"iu th·∫ø\", \"respect\", \"ng∆∞·ª°ng m·ªô\", \"ng·ªçt ng√†o\"\n","]\n","\n","try:\n","    with open(KEYWORDS_FILE, 'w', encoding='utf-8') as f:\n","        json.dump(valid_keywords, f, ensure_ascii=False, indent=2)\n","\n","    with open(WHITELIST_FILE, 'w', encoding='utf-8') as f:\n","        json.dump(positive_keywords, f, ensure_ascii=False, indent=2)\n","\n","except Exception as e:\n","    print(f\"‚ùå L·ªói: {e}\")"]},{"cell_type":"code","source":["# ======================================================\n","# CELL 13: RETRAIN SYSTEM\n","# ======================================================\n","def retrain_system():\n","    print(\"\\nüîÑ [SYSTEM] ƒêang ti·∫øn h√†nh hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh...\")\n","\n","    try:\n","        # 1. Load d·ªØ li·ªáu m·ªõi nh·∫•t\n","        if not os.path.exists(DATASET_FILE):\n","            print(\"‚ùå Kh√¥ng t√¨m th·∫•y file dataset!\")\n","            return\n","\n","        df = pd.read_csv(DATASET_FILE)\n","\n","        # Ki·ªÉm tra d·ªØ li·ªáu\n","        if len(df) < 10: # √çt nh·∫•t 10 d√≤ng m·ªõi train\n","            print(\"‚ö†Ô∏è D·ªØ li·ªáu qu√° √≠t ƒë·ªÉ train l·∫°i.\")\n","            return\n","\n","        print(f\"   - T·ªïng d·ªØ li·ªáu: {len(df)} d√≤ng\")\n","\n","        # 2. L√†m s·∫°ch d·ªØ li·ªáu (Pre-processing)\n","        # L∆∞u √Ω: C·ªôt d·ªØ li·ªáu l√† 'free_text', nh√£n l√† 'label_id'\n","        df = df.dropna(subset=['free_text', 'label_id']) # B·ªè d√≤ng null\n","\n","        # √Åp d·ª•ng h√†m clean_text t·ª´ Cell 4\n","        print(\"   - ƒêang l√†m s·∫°ch vƒÉn b·∫£n...\")\n","        df['clean_text'] = df['free_text'].apply(lambda x: clean_text(str(x)))\n","\n","        # 3. Chia t·∫≠p train/test (80/20) ƒë·ªÉ ƒë√°nh gi√° s∆° b·ªô\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            df['clean_text'], df['label_id'], test_size=0.2, random_state=42\n","        )\n","\n","        # 4. Vector h√≥a (TF-IDF)\n","        print(\"   - ƒêang Vector h√≥a d·ªØ li·ªáu...\")\n","        # T·∫°o vectorizer m·ªõi (c·∫≠p nh·∫≠t t·ª´ v·ª±ng m·ªõi)\n","        vectorizer_new = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n","        X_train_tfidf = vectorizer_new.fit_transform(X_train)\n","        X_test_tfidf = vectorizer_new.transform(X_test)\n","\n","        # 5. Train Model (SVM)\n","        print(\"   - ƒêang Train Model (SVM)...\")\n","        # S·ª≠ d·ª•ng SVC v·ªõi class_weight='balanced' ƒë·ªÉ c√¢n b·∫±ng n·∫øu d·ªØ li·ªáu l·ªách\n","        model_new = SVC(kernel='linear', probability=True, class_weight='balanced', random_state=42)\n","        model_new.fit(X_train_tfidf, y_train)\n","\n","        # 6. ƒê√°nh gi√° s∆° b·ªô\n","        y_pred = model_new.predict(X_test_tfidf)\n","        acc = accuracy_score(y_test, y_pred)\n","        print(f\"‚úÖ Hu·∫•n luy·ªán xong! ƒê·ªô ch√≠nh x√°c m·ªõi: {acc:.2%}\")\n","        # print(classification_report(y_test, y_pred)) # B·∫≠t n·∫øu mu·ªën xem chi ti·∫øt\n","\n","        # 7. L∆∞u Model & Vectorizer\n","        print(\"   - ƒêang l∆∞u file model...\")\n","        joblib.dump(model_new, MODEL_FILE)\n","        joblib.dump(vectorizer_new, VECTORIZER_FILE)\n","\n","        # 8. C·∫¨P NH·∫¨T BI·∫æN TO√ÄN C·ª§C (ƒê·ªÉ Web App d√πng ngay l·∫≠p t·ª©c)\n","        # Khai b√°o global ƒë·ªÉ thay ƒë·ªïi bi·∫øn b√™n ngo√†i h√†m\n","        global model, vectorizer\n","        model = model_new\n","        vectorizer = vectorizer_new\n","\n","        print(\"üöÄ [SUCCESS] H·ªá th·ªëng ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t model m·ªõi th√†nh c√¥ng!\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå L·ªói khi Retrain: {e}\")\n","        import traceback\n","        traceback.print_exc()"],"metadata":{"id":"BQaXwuY0fiX-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m_E9HnQ3Ocse"},"outputs":[],"source":["# ======================================================\n","# CELL 14: MANUAL MERGE\n","# ======================================================\n","def force_merge_and_retrain():\n","    print(\"‚ö° B·∫ÆT ƒê·∫¶U: Quy tr√¨nh g·ªôp d·ªØ li·ªáu an to√†n...\")\n","\n","    # 1. Ki·ªÉm tra file ƒë·∫ßu v√†o\n","    if not os.path.exists(APPROVED_POOL_FILE):\n","        print(\"‚ö†Ô∏è File 'approved_pool.csv' kh√¥ng t·ªìn t·∫°i. Kh√¥ng c√≥ g√¨ ƒë·ªÉ g·ªôp.\")\n","        return\n","\n","    try:\n","        # 2. ƒê·ªçc Dataset Ch√≠nh v√† Pool M·ªõi\n","        # ƒê·ªçc dataset g·ªëc (gi·∫£ s·ª≠ c·ªôt l√†: free_text, label_id)\n","        df_main = pd.read_csv(DATASET_FILE)\n","\n","        # ƒê·ªçc d·ªØ li·ªáu m·ªõi duy·ªát (th∆∞·ªùng c·ªôt l√†: text, label)\n","        df_pool = pd.read_csv(APPROVED_POOL_FILE)\n","\n","        if df_pool.empty:\n","            print(\"‚ö†Ô∏è File pool r·ªóng.\")\n","            return\n","\n","        print(f\"   - Dataset hi·ªán t·∫°i: {len(df_main)} d√≤ng\")\n","        print(f\"   - D·ªØ li·ªáu m·ªõi duy·ªát: {len(df_pool)} d√≤ng\")\n","\n","        # 3. CHU·∫®N H√ìA T√äN C·ªòT (QUAN TR·ªåNG)\n","        # ƒê·ªïi t√™n c·ªôt c·ªßa pool cho kh·ªõp v·ªõi dataset ch√≠nh\n","        # (Ch·ªânh s·ª≠a map_columns n·∫øu t√™n c·ªôt c·ªßa b·∫°n kh√°c)\n","        map_columns = {\n","            'text': 'free_text',      # T√™n b√™n pool -> T√™n b√™n main\n","            'label': 'label_id'       # T√™n b√™n pool -> T√™n b√™n main\n","        }\n","        df_pool = df_pool.rename(columns=map_columns)\n","\n","        # Ch·ªâ l·∫•y ƒë√∫ng c√°c c·ªôt m√† Dataset ch√≠nh ƒëang d√πng\n","        cols_needed = [c for c in df_main.columns if c in df_pool.columns]\n","        df_pool_ready = df_pool[cols_needed]\n","\n","        # 4. G·ªòP V√Ä LO·∫†I B·ªé TR√ôNG L·∫∂P\n","        # N·ªëi 2 b·∫£ng l·∫°i\n","        df_combined = pd.concat([df_main, df_pool_ready], ignore_index=True)\n","\n","        # X√≥a c√°c d√≤ng tr√πng nhau (d·ª±a tr√™n c·ªôt vƒÉn b·∫£n)\n","        before_dedup = len(df_combined)\n","        df_combined = df_combined.drop_duplicates(subset=['free_text'], keep='last')\n","        after_dedup = len(df_combined)\n","\n","        print(f\"   - T·ªïng sau khi g·ªôp: {before_dedup}\")\n","        print(f\"   - Sau khi l·ªçc tr√πng: {after_dedup} (ƒê√£ lo·∫°i {before_dedup - after_dedup} tin r√°c)\")\n","\n","        # 5. L∆ØU L·∫†I FILE CH√çNH\n","        df_combined.to_csv(DATASET_FILE, index=False, encoding='utf-8')\n","        print(f\"‚úÖ ƒê√£ l∆∞u Dataset m·ªõi th√†nh c√¥ng!\")\n","\n","        # 6. D·ªåN D·∫∏P & RETRAIN\n","        os.remove(APPROVED_POOL_FILE)\n","        print(\"üóëÔ∏è ƒê√£ x√≥a file pool t·∫°m.\")\n","\n","        # G·ªçi h√†m Retrain\n","        if 'retrain_system' in globals():\n","            print(\"üîÑ ƒêang g·ªçi h√†m Retrain...\")\n","            retrain_system()\n","        else:\n","            print(\"‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y h√†m 'retrain_system'. H√£y ch·∫°y Cell ch·ª©a h√†m Retrain tr∆∞·ªõc!\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå L·ªói nghi√™m tr·ªçng khi g·ªôp d·ªØ li·ªáu: {e}\")\n","        # In ra chi ti·∫øt l·ªói ƒë·ªÉ debug\n","        import traceback\n","        traceback.print_exc()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qZVYRVap9sB"},"outputs":[],"source":["# ======================================================\n","# CELL 15: ACTIVE LEARNING\n","# ======================================================\n","import pandas as pd\n","import os\n","\n","FEEDBACK_FILE = os.path.join(DIR_DATA, \"user_feedback.csv\")\n","APPROVED_POOL_FILE = os.path.join(DIR_DATA, \"approved_pool.csv\")\n","\n","def is_spam_or_duplicate(text):\n","    \"\"\"\n","    Tr·∫£ v·ªÅ True n·∫øu l√† Spam ho·∫∑c ƒë√£ t·ªìn t·∫°i.\n","    \"\"\"\n","    # Text ƒë·∫ßu v√†o ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch ·ªü h√†m g·ªçi, nh∆∞ng clean l·∫°i cho ch·∫Øc\n","    text = str(text).strip()\n","\n","    if not text: return True\n","\n","    # 1. L·ªåC R√ÅC (SPAM FILTER)\n","    if len(text.split()) < 2:\n","        print(f\"üö´ T·ª´ ch·ªëi (Qu√° ng·∫Øn): {text}\")\n","        return True\n","\n","    if len(text) > 15 and ' ' not in text:\n","        print(f\"üö´ T·ª´ ch·ªëi (Spam k√Ω t·ª±): {text}\")\n","        return True\n","\n","    # 2. CH·ªêNG TR√ôNG L·∫∂P (DUPLICATE CHECK)\n","    # Ki·ªÉm tra trong Feedback\n","    if os.path.exists(FEEDBACK_FILE):\n","        try:\n","            df_fb = pd.read_csv(FEEDBACK_FILE)\n","            if text in df_fb['text'].values:\n","                print(f\"üö´ T·ª´ ch·ªëi (ƒê√£ c√≥ trong Feedback): {text}\")\n","                return True\n","        except: pass\n","\n","    # Ki·ªÉm tra trong Pool\n","    if os.path.exists(APPROVED_POOL_FILE):\n","        try:\n","            df_pool = pd.read_csv(APPROVED_POOL_FILE)\n","            col_name = 'free_text' if 'free_text' in df_pool.columns else 'text'\n","            if text in df_pool[col_name].values:\n","                print(f\"üö´ T·ª´ ch·ªëi (ƒê√£ c√≥ trong Pool): {text}\")\n","                return True\n","        except: pass\n","\n","    # Ki·ªÉm tra trong Dataset g·ªëc\n","    if os.path.exists(DATASET_FILE):\n","        try:\n","            df_main = pd.read_csv(DATASET_FILE, usecols=['free_text'])\n","            if text in df_main['free_text'].values:\n","                print(f\"üö´ T·ª´ ch·ªëi (ƒê√£ c√≥ trong Dataset): {text}\")\n","                return True\n","        except: pass\n","\n","    return False\n","\n","def save_to_feedback_pool(original_text, predicted_label, user_status_text):\n","    \"\"\"L∆∞u d·ªØ li·ªáu v√†o h·ªì s∆° ch·ªù duy·ªát\"\"\"\n","\n","    # --- [QUAN TR·ªåNG] L√ÄM S·∫†CH TEXT TR∆Ø·ªöC KHI L√ÄM B·∫§T C·ª® G√å ---\n","    # 1. √âp ki·ªÉu chu·ªói\n","    clean_txt = str(original_text)\n","    # 2. Bi·∫øn xu·ªëng d√≤ng th√†nh d·∫•u c√°ch (Ch·ªëng l·ªách d√≤ng CSV)\n","    clean_txt = clean_txt.replace('\\n', ' ').replace('\\r', ' ')\n","    # 3. C·∫Øt kho·∫£ng tr·∫Øng th·ª´a ƒë·∫ßu ƒëu√¥i\n","    clean_txt = clean_txt.strip()\n","    # ----------------------------------------------------------\n","\n","    # Ki·ªÉm tra Spam/Tr√πng l·∫∑p b·∫±ng text ƒê√É L√ÄM S·∫†CH\n","    if is_spam_or_duplicate(clean_txt):\n","        return False, \"D·ªØ li·ªáu b·ªã lo·∫°i b·ªè do l√† Spam ho·∫∑c Tr√πng l·∫∑p.\"\n","\n","    # L∆∞u v√†o DataFrame b·∫±ng text ƒê√É L√ÄM S·∫†CH (clean_txt)\n","    new_entry = pd.DataFrame([{\n","        'text': clean_txt,  # <--- D√πng clean_txt thay v√¨ original_text\n","        'label': predicted_label,\n","        'user_status': user_status_text,\n","        'timestamp': pd.Timestamp.now()\n","    }])\n","\n","    if not os.path.exists(FEEDBACK_FILE):\n","        new_entry.to_csv(FEEDBACK_FILE, index=False, encoding='utf-8')\n","    else:\n","        new_entry.to_csv(FEEDBACK_FILE, mode='a', header=False, index=False, encoding='utf-8')\n","\n","    return True, \"ƒê√£ g·ª≠i b√°o c√°o cho Admin!\"\n","\n","def delete_feedback(idx):\n","    if os.path.exists(FEEDBACK_FILE):\n","        try:\n","            df_fb = pd.read_csv(FEEDBACK_FILE)\n","            if 0 <= idx < len(df_fb):\n","                df_fb = df_fb.drop(idx).reset_index(drop=True)\n","                df_fb.to_csv(FEEDBACK_FILE, index=False, encoding='utf-8')\n","                return True\n","        except: return False\n","    return False\n","\n","def check_and_trigger_retrain():\n","    \"\"\"Ki·ªÉm tra n·∫øu ƒë·ªß 100 c√¢u ƒë√£ duy·ªát th√¨ g·ªôp v√†o dataset ch√≠nh v√† retrain\"\"\"\n","    if not os.path.exists(APPROVED_POOL_FILE): return\n","\n","    try:\n","        df_pool = pd.read_csv(APPROVED_POOL_FILE)\n","        if len(df_pool) >= 100:\n","            print(f\"üöÄ ƒê√£ ƒë·∫°t ng∆∞·ª°ng {len(df_pool)} c√¢u. K√≠ch ho·∫°t Retrain...\")\n","\n","            # G·ªçi h√†m g·ªôp an to√†n ·ªü Cell 10 (n·∫øu c√≥)\n","            if 'force_merge_and_retrain' in globals():\n","                force_merge_and_retrain()\n","            else:\n","                # Fallback n·∫øu ch∆∞a ch·∫°y Cell 10\n","                print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y h√†m merge an to√†n.\")\n","        else:\n","            print(f\"üìä Ti·∫øn ƒë·ªô: {len(df_pool)}/100 c√¢u.\")\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è L·ªói check retrain: {e}\")\n","\n","def move_to_official_dataset(text, final_label):\n","    # Text input ·ªü ƒë√¢y l·∫•y t·ª´ file Feedback n√™n ƒë√£ s·∫°ch, nh∆∞ng clean l·∫°i cho ch·∫Øc\n","    text = str(text).replace('\\n', ' ').strip()\n","\n","    # 1. Th√™m v√†o Approved Pool\n","    # L∆∞u √Ω: C·ªôt dataset ch√≠nh l√† 'free_text' v√† 'label_id'\n","    new_data = pd.DataFrame([[text, final_label]], columns=['free_text', 'label_id'])\n","\n","    if not os.path.exists(APPROVED_POOL_FILE):\n","        new_data.to_csv(APPROVED_POOL_FILE, index=False, encoding='utf-8')\n","    else:\n","        new_data.to_csv(APPROVED_POOL_FILE, mode='a', header=False, index=False, encoding='utf-8')\n","\n","    # 2. X√≥a c√¢u ƒë√≥ kh·ªèi file Feedback\n","    if os.path.exists(FEEDBACK_FILE):\n","        df_fb = pd.read_csv(FEEDBACK_FILE)\n","        df_fb = df_fb[df_fb['text'] != text]\n","        df_fb.to_csv(FEEDBACK_FILE, index=False, encoding='utf-8')\n","\n","    check_and_trigger_retrain()\n","    return True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COIEJi6Y3X9l"},"outputs":[],"source":["# ======================================================\n","# CELL 16: WEB APP\n","# ======================================================\n","# 1. C·∫•u h√¨nh\n","NGROK_TOKEN = \"(PASTE_YOUR_TOKEN_HERE)\"\n","ADMIN_PASSWORD = \"admin123\"\n","SECRET_KEY = \"khoa_bi_mat_cho_session\"\n","\n","# Setup Ngrok\n","ngrok.set_auth_token(NGROK_TOKEN)\n","ngrok.kill()\n","\n","# --- H√ÄM B·ªî TR·ª¢ ---\n","def app_clean_text(text):\n","    if 'clean_text' in globals(): return clean_text(text)\n","    return re.sub(r'[^\\w\\s]', ' ', str(text).lower())\n","\n","def app_check_english(text):\n","    if 'scan_english_offensive' in globals(): return scan_english_offensive(text)\n","    return False, 0, None\n","\n","def check_violation_vietnamese(text):\n","    cleaned = app_clean_text(text)\n","    detected = []\n","    if 'KEYWORDS' in globals():\n","        for category, content in KEYWORDS.items():\n","            is_violated = False\n","            if isinstance(content, list):\n","                for word in content:\n","                    if word in cleaned: is_violated = True; break\n","            elif isinstance(content, dict) and \"T·ª´ kh√≥a c·ªë ƒë·ªãnh\" in content:\n","                for word in content[\"T·ª´ kh√≥a c·ªë ƒë·ªãnh\"]:\n","                    if word in cleaned: is_violated = True; break\n","            if is_violated: detected.append(category)\n","    return list(set(detected)), cleaned\n","\n","# --- FLASK APP ---\n","app = Flask(__name__)\n","app.secret_key = SECRET_KEY\n","\n","HTML_TEMPLATE = \"\"\"\n","<!DOCTYPE html>\n","<html>\n","<head>\n","    <title>H·ªá th·ªëng ki·ªÉm duy·ªát Ti·∫øng Vi·ªát</title>\n","    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n","    <style>\n","        body { font-family: 'Segoe UI', sans-serif; background: #f8fafc; padding: 20px; }\n","        .container { max-width: 950px; margin: 0 auto; background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 25px rgba(0,0,0,0.05); }\n","        h2 { text-align: center; color: #1e293b; margin-bottom: 25px; }\n","        textarea { width: 100%; height: 120px; padding: 15px; border: 2px solid #e2e8f0; border-radius: 10px; font-size: 16px; box-sizing: border-box; transition: 0.3s; }\n","        textarea:focus { border-color: #3b82f6; outline: none; }\n","\n","        .btn { display: block; width: 100%; padding: 12px; border: none; border-radius: 8px; font-size: 16px; font-weight: bold; cursor: pointer; transition: 0.2s; text-align: center; text-decoration: none; box-sizing: border-box;}\n","        .btn-check { background: #3b82f6; color: white; margin-top: 15px; }\n","        .btn-check:hover { background: #2563eb; }\n","\n","        .result-box { margin-top: 25px; padding: 20px; border-radius: 10px; text-align: center; border: 2px solid transparent; animation: fadeIn 0.5s; }\n","        .SAFE { background: #dcfce7; color: #15803d; border-color: #86efac; }\n","        .WARNING { background: #ffedd5; color: #c2410c; border-color: #fdba74; }\n","        .DANGER { background: #fee2e2; color: #b91c1c; border-color: #fca5a5; }\n","\n","        .admin-link { display: block; text-align: center; margin-top: 30px; color: #94a3b8; text-decoration: none; font-size: 14px; }\n","\n","        /* Admin Styles */\n","        table { width: 100%; border-collapse: collapse; margin-top: 20px; font-size: 14px; }\n","        th { background: #f1f5f9; padding: 12px; text-align: left; color: #475569; }\n","        td { border-bottom: 1px solid #e2e8f0; padding: 12px; vertical-align: top; }\n","\n","        /* Action Buttons */\n","        .act-btn { padding: 5px 10px; border-radius: 5px; text-decoration: none; font-size: 11px; margin-right: 3px; display: inline-block; color: white; font-weight: bold;}\n","        .act-clean { background: #22c55e; }\n","        .act-offen { background: #f59e0b; }\n","        .act-hate { background: #ef4444; }\n","        .act-del { color: #64748b; font-size: 12px; margin-left: 5px; text-decoration: underline;}\n","\n","        /* Tags for Admin */\n","        .tag { font-size: 11px; padding: 3px 8px; border-radius: 10px; font-weight: bold; display: inline-block; }\n","        .tag-safe { background: #dcfce7; color: #166534; border: 1px solid #86efac; }\n","        .tag-warn { background: #ffedd5; color: #9a3412; border: 1px solid #fdba74; }\n","        .tag-hate { background: #fee2e2; color: #991b1b; border: 1px solid #fca5a5; }\n","\n","        /* --- MONKEY LOGIN STYLES --- */\n","        .monkey-icon { font-size: 60px; text-align: center; margin-bottom: 10px; cursor: pointer; transition: transform 0.2s; display: block; }\n","        .monkey-icon:hover { transform: scale(1.1); }\n","\n","        .password-wrapper { position: relative; margin-bottom: 15px; }\n","        .password-wrapper input { width: 100%; padding: 12px; border: 1px solid #ccc; border-radius: 8px; box-sizing: border-box; font-size: 16px; }\n","        .toggle-icon { position: absolute; right: 15px; top: 50%; transform: translateY(-50%); cursor: pointer; font-size: 18px; user-select: none; z-index: 2; }\n","\n","        @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }\n","    </style>\n","</head>\n","<body>\n","    <div class=\"container\">\n","        {% if page == 'home' %}\n","            <h2>üõ°Ô∏è Ki·ªÉm duy·ªát N·ªôi dung Ti·∫øng Vi·ªát</h2>\n","            <form method=\"post\">\n","                <textarea name=\"txt\" placeholder=\"Nh·∫≠p b√¨nh lu·∫≠n c·ªßa b·∫°n t·∫°i ƒë√¢y...\">{{original}}</textarea>\n","                <button type=\"submit\" class=\"btn btn-check\">KI·ªÇM TRA NGAY</button>\n","            </form>\n","            {% if res %}\n","                <div class=\"result-box {{status}}\">\n","                    <h3 style=\"margin:0; font-size: 22px;\">{{res}}</h3>\n","                    {% if debug %}<p style=\"margin-top:10px; font-size:13px; opacity:0.8;\">(AI ƒë√£ x·ª≠ l√Ω: \"{{debug}}\")</p>{% endif %}\n","\n","                    <div style=\"margin-top: 15px;\">\n","                        <button style=\"background:none; border:none; text-decoration:underline; cursor:pointer; color:inherit; font-size:13px;\"\n","                                onclick=\"reportError('{{status}}', {{pred_id}})\">üì¢ B√°o c√°o k·∫øt qu·∫£ sai</button>\n","                    </div>\n","                </div>\n","            {% endif %}\n","            <a href=\"/admin\" class=\"admin-link\">Khu v·ª±c qu·∫£n tr·ªã vi√™n</a>\n","\n","        {% elif page == 'login' %}\n","            <div id=\"monkey\" class=\"monkey-icon\">üôà</div>\n","\n","            <h2>üîê ƒêƒÉng nh·∫≠p Admin</h2>\n","            <form method=\"post\">\n","                <div class=\"password-wrapper\">\n","                    <input type=\"password\" id=\"passwordInput\" name=\"password\" placeholder=\"M·∫≠t kh·∫©u\">\n","                    <span class=\"toggle-icon\" onclick=\"togglePassword()\">üëÅÔ∏è</span>\n","                </div>\n","                <button type=\"submit\" class=\"btn btn-check\">ƒêƒÉng nh·∫≠p</button>\n","            </form>\n","            {% if error %}<p style=\"color:red; text-align:center; margin-top:10px\">{{error}}</p>{% endif %}\n","\n","        {% elif page == 'admin' %}\n","            <h2>‚öôÔ∏è Qu·∫£n L√Ω Ph·∫£n H·ªìi</h2>\n","            <div style=\"text-align:right\"><a href=\"/logout\" style=\"color:red; text-decoration:none\">ƒêƒÉng xu·∫•t</a></div>\n","            {% if feedbacks.empty %}\n","                <p style=\"text-align:center; color:#64748b; margin-top:30px\">Hi·ªán ch∆∞a c√≥ ph·∫£n h·ªìi n√†o.</p>\n","            {% else %}\n","                <table>\n","                    <thead>\n","                        <tr>\n","                            <th style=\"width:45%\">N·ªôi dung ng∆∞·ªùi d√πng</th>\n","                            <th style=\"width:20%\">AI D·ª± ƒëo√°n g·ªëc</th>\n","                            <th>Ch·ªçn nh√£n ch√≠nh x√°c</th>\n","                        </tr>\n","                    </thead>\n","                    <tbody>\n","                    {% for idx, row in feedbacks.iterrows() %}\n","                        <tr>\n","                            <td>{{ row['text'] }}</td>\n","\n","                            <td>\n","                                {% if row['label'] == 0 %}\n","                                    <span class=\"tag tag-safe\">Clean</span>\n","                                {% elif row['label'] == 1 %}\n","                                    <span class=\"tag tag-warn\">Offensive</span>\n","                                {% else %}\n","                                    <span class=\"tag tag-hate\">Hate</span>\n","                                {% endif %}\n","                            </td>\n","\n","                            <td>\n","                                <div style=\"margin-bottom:5px; font-size:11px; color:#64748b\">Duy·ªát l√†:</div>\n","                                <a href=\"/approve?idx={{idx}}&label=0\" class=\"act-btn act-clean\">Clean</a>\n","                                <a href=\"/approve?idx={{idx}}&label=1\" class=\"act-btn act-offen\">Offensive</a>\n","                                <a href=\"/approve?idx={{idx}}&label=2\" class=\"act-btn act-hate\">Hate</a>\n","                                <br>\n","                                <a href=\"/delete?idx={{idx}}\" class=\"act-del\">üóëÔ∏è X√≥a r√°c</a>\n","                            </td>\n","                        </tr>\n","                    {% endfor %}\n","                    </tbody>\n","                </table>\n","            {% endif %}\n","        {% endif %}\n","    </div>\n","    <script>\n","        function reportError(ai_status, pred_id) {\n","            var txt = document.querySelector(\"textarea\").value;\n","            var statusMsg = \"B√°o l·ªói (\" + ai_status + \")\";\n","\n","            fetch('/send-feedback', {\n","                method: 'POST',\n","                headers: {'Content-Type': 'application/json'},\n","                body: JSON.stringify({\n","                    text: txt,\n","                    label: pred_id,\n","                    user_status: statusMsg\n","                })\n","            }).then(() => alert(\"‚úÖ ƒê√£ g·ª≠i b√°o c√°o! C·∫£m ∆°n b·∫°n ƒë√£ ƒë√≥ng g√≥p.\"));\n","        }\n","\n","        // --- MONKEY LOGIN SCRIPT ---\n","        function togglePassword() {\n","            var pInput = document.getElementById(\"passwordInput\");\n","            var mIcon = document.getElementById(\"monkey\");\n","            if (pInput.type === \"password\") {\n","                pInput.type = \"text\";\n","                if(mIcon) mIcon.innerText = \"üêµ\"; // M·ªü m·∫Øt\n","            } else {\n","                pInput.type = \"password\";\n","                if(mIcon) mIcon.innerText = \"üôà\"; // Che m·∫Øt\n","            }\n","        }\n","\n","        // T·ª± ƒë·ªông che m·∫Øt khi click v√†o √¥ input (n·∫øu ƒëang ·ªü mode password)\n","        var pInput = document.getElementById(\"passwordInput\");\n","        if(pInput) {\n","            pInput.addEventListener('focus', function() {\n","                var mIcon = document.getElementById(\"monkey\");\n","                if (this.type === \"password\" && mIcon) mIcon.innerText = \"üôà\";\n","            });\n","        }\n","    </script>\n","</body>\n","</html>\n","\"\"\"\n","\n","# --- LOGIC X·ª¨ L√ù CH√çNH ---\n","@app.route('/', methods=['GET', 'POST'])\n","def index():\n","    res, status, debug, original, pred_id = \"\", \"\", \"\", \"\", 0\n","    if request.method == 'POST':\n","        try:\n","            original = request.form['txt']\n","            if not original.strip():\n","                return render_template_string(HTML_TEMPLATE, page='home', res=\"Vui l√≤ng nh·∫≠p n·ªôi dung!\", status=\"WARNING\")\n","\n","            is_eng_bad, eng_label, eng_word = app_check_english(original)\n","\n","            cleaned = app_clean_text(original)\n","            debug = cleaned\n","            violation_list, _ = check_violation_vietnamese(original)\n","\n","            seq = tokenizer.texts_to_sequences([cleaned])\n","            pad = pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n","            ai_pred = model.predict(pad, verbose=0)\n","            pred_id = int(np.argmax(ai_pred))\n","\n","            CRITICAL = [\"Ch√≠nh tr·ªã / Nh·∫°y c·∫£m\", \"K√≠ch ƒë·ªông / B·∫°o l·ª±c\", \"C·ªï x√∫y / X√∫i gi·ª•c\"]\n","            has_critical = any(err in violation_list for err in CRITICAL)\n","\n","            if has_critical:\n","                status = \"DANGER\"; res = f\"üö´ VI PH·∫†M NGHI√äM TR·ªåNG: {', '.join(violation_list)}\"\n","            elif is_eng_bad:\n","                status = \"WARNING\"; res = f\"‚ö†Ô∏è T·ª™ NH·∫†Y C·∫¢M (Ti·∫øng Anh): '{eng_word}'\"; pred_id = 1\n","            elif violation_list:\n","                status = \"WARNING\"; res = f\"‚ö†Ô∏è T·ª™ KH√ìA NH·∫†Y C·∫¢M: {', '.join(violation_list)}\"\n","            elif pred_id == 2:\n","                status = \"DANGER\"; res = \"üö´ NG√îN T·ª™ TH√ô GH√âT\"\n","            elif pred_id == 1:\n","                status = \"WARNING\"; res = \"‚ö†Ô∏è N·ªòI DUNG X√öC PH·∫†M\"\n","            else:\n","                status = \"SAFE\"; res = \"‚úÖ N·ªòI DUNG S·∫†CH\"\n","\n","        except Exception as e:\n","            status = \"DANGER\"; res = f\"L·ªói h·ªá th·ªëng: {e}\"\n","\n","    return render_template_string(HTML_TEMPLATE, page='home', res=res, status=status, debug=debug, original=original, feedbacks=pd.DataFrame(), pred_id=pred_id)\n","\n","@app.route('/send-feedback', methods=['POST'])\n","def handle_feedback():\n","    data = request.json\n","    if 'save_to_feedback_pool' in globals():\n","        save_to_feedback_pool(data['text'], data.get('label', 0), data.get('user_status', 'REPORT'))\n","    return jsonify({\"status\": \"ok\"})\n","\n","@app.route('/login', methods=['GET', 'POST'])\n","def login():\n","    if request.method == 'POST':\n","        if request.form['password'] == ADMIN_PASSWORD:\n","            session['logged_in'] = True\n","            return redirect(url_for('admin_view'))\n","        return render_template_string(HTML_TEMPLATE, page='login', error=\"Sai m·∫≠t kh·∫©u\")\n","    return render_template_string(HTML_TEMPLATE, page='login')\n","\n","@app.route('/admin')\n","def admin_view():\n","    if not session.get('logged_in'): return redirect(url_for('login'))\n","    df_fb = pd.DataFrame()\n","    if 'FEEDBACK_FILE' in globals() and os.path.exists(FEEDBACK_FILE):\n","        try: df_fb = pd.read_csv(FEEDBACK_FILE)\n","        except: pass\n","    return render_template_string(HTML_TEMPLATE, page='admin', feedbacks=df_fb)\n","\n","@app.route('/approve')\n","def approve():\n","    if not session.get('logged_in'): return redirect(url_for('login'))\n","    idx = int(request.args.get('idx'))\n","    label = int(request.args.get('label'))\n","    if 'move_to_official_dataset' in globals() and 'FEEDBACK_FILE' in globals():\n","        try:\n","            df_fb = pd.read_csv(FEEDBACK_FILE)\n","            move_to_official_dataset(df_fb.iloc[idx]['text'], label)\n","        except: pass\n","    return redirect(url_for('admin_view'))\n","\n","@app.route('/delete')\n","def delete():\n","    if not session.get('logged_in'): return redirect(url_for('login'))\n","    idx = int(request.args.get('idx'))\n","    if 'delete_feedback' in globals(): delete_feedback(idx)\n","    return redirect(url_for('admin_view'))\n","\n","@app.route('/logout')\n","def logout():\n","    session.pop('logged_in', None)\n","    return redirect(url_for('login'))\n","\n","try: ngrok.kill()\n","except: pass\n","\n","try:\n","    public_url = ngrok.connect(5000).public_url\n","    print(\"=\"*60)\n","    print(f\"üëâ TRANG NG∆Ø·ªúI D√ôNG: {public_url}\")\n","    print(f\"üîê TRANG QU·∫¢N TR·ªä:   {public_url}/admin\")\n","    print(\"=\"*60)\n","    app.run(port=5000, debug=False)\n","except Exception as e:\n","    print(f\"‚ùå L·ªói: {e}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNBVK5rISNay043Gq7yjPDm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMWCJDC73d+mb17vP9iaV+p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VIpw0Wu5by_v","collapsed":true},"outputs":[],"source":["# ======================================================\n","# CELL 1: K·∫æT N·ªêI GOOGLE DRIVE\n","# ======================================================\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# ======================================================\n","# CELL 2: C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N (FINAL STRUCTURE)\n","# ======================================================\n","import os\n","\n","# 1. Th∆∞ m·ª•c g·ªëc\n","BASE_PATH = \"/content/drive/MyDrive/Project_HateSpeech\"\n","\n","# 2. ƒê·ªãnh nghƒ©a c√°c th∆∞ m·ª•c con\n","DIR_DATA      = f\"{BASE_PATH}/dataset\"\n","DIR_KEYWORD   = f\"{BASE_PATH}/keyword\"\n","DIR_EMBEDDING = f\"{BASE_PATH}/embedding\"\n","DIR_MODEL     = f\"{BASE_PATH}/model\"\n","DIR_CONFIG    = f\"{BASE_PATH}/config\"\n","\n","# T·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c (n·∫øu ch∆∞a c√≥)\n","for path in [DIR_DATA, DIR_KEYWORD, DIR_EMBEDDING, DIR_MODEL, DIR_CONFIG]:\n","    os.makedirs(path, exist_ok=True)\n","\n","# 3. ƒê∆∞·ªùng d·∫´n chi ti·∫øt t·ªõi t·ª´ng file\n","# --- Nh√≥m D·ªØ li·ªáu ---\n","DATASET_FILE     = f\"{DIR_DATA}/dataset.csv\"\n","\n","# --- Nh√≥m T√†i nguy√™n ---\n","KEYWORDS_FILE    = f\"{DIR_KEYWORD}/keywords.json\"\n","WHITELIST_FILE   = f\"{DIR_KEYWORD}/whitelist.json\"\n","\n","# --- Nh√≥m Vector h√≥a ---\n","EMBEDDING_FILE   = f\"{DIR_EMBEDDING}/cc.vi.300.vec\"\n","\n","# --- Nh√≥m Model ---\n","MODEL_FILE       = f\"{DIR_MODEL}/hate_speech_model.h5\"\n","TOKENIZER_FILE   = f\"{DIR_MODEL}/tokenizer.pickle\"\n","\n","# --- Nh√≥m C·∫•u h√¨nh ---\n","NGROK_TOKEN_FILE = f\"{DIR_CONFIG}/ngrok_token.txt\"\n","\n","# 4. Tham s·ªë Model\n","MAX_WORDS = 20000\n","MAX_LEN   = 100\n","EMBED_DIM = 300\n","\n","print(f\"‚úÖ ƒê√£ c·∫≠p nh·∫≠t c·∫•u tr√∫c th∆∞ m·ª•c ho√†n ch·ªânh!\")\n","print(f\"üìÇ Dataset: {DIR_DATA}\")\n","print(f\"üìÇ Keyword:  {DIR_KEYWORD}\")\n","print(f\"üìÇ Embedding:  {DIR_EMBEDDING}\")\n","print(f\"üìÇ Model:  {DIR_MODEL}\")\n","print(f\"üìÇ Config:  {DIR_CONFIG}\")"],"metadata":{"id":"xzjqR0QecCz5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# ======================================================\n","# CELL T·∫†O FILE TEENCODE (JSON)\n","# ======================================================\n","teencode_dict = {\n","    \"ctrai\": \"con trai\",\n","    \"kh√¥g\": \"kh√¥ng\",\n","    \"bme\": \"b·ªë m·∫π\",\n","    \"cta\": \"ch√∫ng ta\",\n","    \"mih\": \"m√¨nh\",\n","    \"mqh\": \"m·ªëi quan h·ªá\",\n","    \"cgai\": \"con g√°i\",\n","    \"nh·ªØg\": \"nh·ªØng\",\n","    \"mng\": \"m·ªçi ng∆∞·ªùi\",\n","    \"svtn\": \"sinh vi√™n t√¨nh nguy·ªán\",\n","    \"sv\": \"sinh vi√™n\",\n","    \"r\": \"r·ªìi\",\n","    \"th\": \"th√¥i\",\n","    \"p√°c\": \"b√°c\",\n","    \"qtam\": \"quan t√¢m\",\n","    \"th∆∞∆°g\": \"th∆∞∆°ng\",\n","    \"qt√¢m\": \"quan t√¢m\",\n","    \"chug\": \"chung\",\n","    \"tr∆∞·ªùg\": \"tr∆∞·ªùng\",\n","    \"thoy\": \"th√¥i\",\n","    \"vailoz\": \"v√£i l·ªìn\",\n","    \"ƒëki\": \"ƒëƒÉng k√Ω\",\n","    \"clb\": \"c√¢u l·∫°c b·ªô\",\n","    \"ƒëb\": \"ƒë·∫ßu bu·ªìi\",\n","    \"db\": \"ƒë·∫ßu bu·ªìi\",\n","    \"atsm\": \"·∫£o t∆∞·ªüng s·ª©c m·∫°nh\",\n","    \"·∫°k\": \"·∫°\",\n","    \"dell\": \"ƒë√©o\",\n","    \"thg\": \"th·∫±ng\",\n","    \"nma\": \"nh∆∞ng m√†\",\n","    \"nhma\": \"nh∆∞ng m√†\",\n","    \"edit\": \"ch·ªânh s·ª≠a\",\n","    \"cv\": \"c√¥ng vi·ªác\",\n","    \"vch\": \"v√£i ch∆∞·ªüng\",\n","    \"c√πg\": \"c√πng\",\n","    \"pn\": \"b·∫°n\",\n","    \"z\": \"v·∫≠y\",\n","    \"v\": \"v·∫≠y\",\n","    \"zzz\": \"ng·ªß\",\n","    \"pjt\": \"bi·∫øt\",\n","    \"thjk\": \"th√≠ch\",\n","    \"keke\": \"c∆∞·ªùi\",\n","    \"ktra\": \"ki·ªÉm tra\",\n","    \"ktx\": \"k√Ω t√∫c x√°\",\n","    \"nek\": \"n√®\",\n","    \"cg√°i\": \"con g√°i\",\n","    \"nthe\": \"nh∆∞ th·∫ø\",\n","    \"ch√∫g\": \"ch√∫ng\",\n","    \"k√°i\": \"c√°i\",\n","    \"t√¨h\": \"t√¨nh\",\n","    \"ph√≤g\": \"ph√≤ng\",\n","    \"l√≤g\": \"l√≤ng\",\n","    \"t·ª´g\": \"t·ª´ng\",\n","    \"r·∫±g\": \"r·∫±ng\",\n","    \"s·ªëg\": \"s·ªëng\",\n","    \"thuj\": \"th√¥i\",\n","    \"thu∆°ng\": \"th∆∞∆°ng\",\n","    \"c√†g\": \"c√†ng\",\n","    \"ƒëky\": \"ƒëƒÉng k√Ω\",\n","    \"b·∫±g\": \"b·∫±ng\",\n","    \"svi√™n\": \"sinh vi√™n\",\n","    \"viral\": \"n·ªïi ti·∫øng\",\n","    \"mxh\": \"m·∫°ng x√£ h·ªôi\",\n","    \"√°k\": \"√°\",\n","    \"mm\": \"m·∫π m√†y\",\n","    \"ƒë√°g\": \"ƒë√°ng\",\n","    \"nvay\": \"nh∆∞ v·∫≠y\",\n","    \"nhjeu\": \"nhi·ªÅu\",\n","    \"xg\": \"xu·ªëng\",\n","    \"z·ªìi\": \"r·ªìi\",\n","    \"trag\": \"trang\",\n","    \"z·ªØ\": \"d·ªØ\",\n","    \"atrai\": \"anh trai\",\n","    \"kte\": \"kinh t·∫ø\",\n","    \"ƒë·ªôg\": \"ƒë·ªông\",\n","    \"lmht\": \"li√™n minh huy·ªÅn tho·∫°i\",\n","    \"g·∫Øg\": \"g·∫Øng\",\n","    \"ƒëzai\": \"ƒë·∫πp trai\",\n","    \"thgian\": \"th·ªùi gian\",\n","    \"plz\": \"l√†m ∆°n\",\n","    \"ƒë·ªìg\": \"ƒë·ªìng\",\n","    \"btrai\": \"b·∫°n trai\",\n","    \"nth√™\": \"nh∆∞ th·∫ø\",\n","    \"h√¨h√¨\": \"c∆∞·ªùi\",\n","    \"v·ªçg\": \"v·ªçng\",\n","    \"hihe\": \"c∆∞·ªùi\",\n","    \"ƒë√¥g\": \"ƒë√¥ng\",\n","    \"rƒÉg\": \"rƒÉng\",\n","    \"th∆∞·ªùg\": \"th∆∞·ªùng\",\n","    \"tc·∫£m\": \"t√¨nh c·∫£m\",\n","    \"ƒë·ª©g\": \"ƒë·ª©ng\",\n","    \"ksao\": \"kh√¥ng sao\",\n","    \"dz\": \"ƒë·∫πp trai\",\n","    \"hjxhjx\": \"hix hix\",\n","    \"cm√†y\": \"ch√∫ng m√†y\",\n","    \"xu·ªëg\": \"xu·ªëng\",\n","    \"nk∆∞\": \"nh∆∞\",\n","    \"lquan\": \"li√™n quan\",\n","    \"lqmb\": \"li√™n qu√¢n mobile\",\n","    \"mlbb\": \"mobile legend bang bang\",\n","    \"ti·∫øg\": \"ti·∫øng\",\n","    \"hajz\": \"haizz\",\n","    \"cjv\": \"c√°i g√¨ v·∫≠y\",\n","    \"ccjv\": \"con c·∫∑c g√¨ v·∫≠y\",\n","    \"xih\": \"xinh\",\n","    \"h√¨h\": \"h√¨nh\",\n","    \"th√†h\": \"th√†nh\",\n","    \"ngke\": \"nghe\",\n","    \"dz·∫≠y\": \"d·∫≠y\",\n","    \"teencode\": \"tin c·ªët\",\n","    \"tn√†o\": \"th·∫ø n√†o\",\n","    \"t∆∞·ªüg\": \"t∆∞·ªüng\",\n","    \"ctrinh\": \"ch∆∞∆°ng tr√¨nh\",\n","    \"phog\": \"phong\",\n","    \"h√¥g\": \"kh√¥ng\",\n","    \"z√¨a\": \"g√¨\",\n","    \"k≈©g\": \"c≈©ng\",\n","    \"ntnao\": \"nh∆∞ th·∫ø n√†o\",\n","    \"tr·ªçg\": \"tr·ªçng\",\n","    \"nth·∫ø\": \"nh∆∞ th·∫ø\",\n","    \"nƒÉg\": \"nƒÉng\",\n","    \"ngƒë√≥\": \"ng∆∞·ªùi ƒë√≥\",\n","    \"lquen\": \"l√†m quen\",\n","    \"ri√™g\": \"ri√™ng\",\n","    \"ngag\": \"ngang\",\n","    \"h√™h√™\": \"c∆∞·ªùi\",\n","    \"h·ªâu\": \"hi·ªÉu\",\n","    \"bnhiu\": \"bao nhi√™u\",\n","    \"ng·ªëk\": \"ng·ªëc\",\n","    \"k·∫≠u\": \"c·∫≠u\",\n","    \"highland\": \"qu√°n c√† ph√™\",\n","    \"hlv\": \"hu·∫•n luy·ªán vi√™n\",\n","    \"kqua\": \"k·∫øt qu·∫£\",\n","    \"htrc\": \"h√¥m tr∆∞·ªõc\",\n","    \"ƒë·ªãh\": \"ƒë·ªãnh\",\n","    \"gƒë√¨nh\": \"gia ƒë√¨nh\",\n","    \"gi·ªëg\": \"gi·ªëng\",\n","    \"cs·ªëng\": \"cu·ªôc s·ªëng\",\n","    \"cuti\": \"d·ªÖ th∆∞∆°ng\",\n","    \"xug\": \"xung\",\n","    \"z√πi\": \"r·ªìi\",\n","    \"bnhi√™u\": \"bao nhi√™u\",\n","    \"cb·ªã\": \"chu·∫©n b·ªã\",\n","    \"k√≤n\": \"c√≤n\",\n","    \"bu√¥g\": \"bu√¥ng\",\n","    \"bulul\": \"b√∫ l·ªìn\",\n","    \"csong\": \"cu·ªôc s·ªëng\",\n","    \"solo\": \"m·ªôt m√¨nh\",\n","    \"1v1\": \"ƒë·ªëi ƒë·∫ßu\",\n","    \"1vs1\": \"ƒë·ªëi ƒë·∫ßu\",\n","    \"ch√†g\": \"ch√†ng\",\n","    \"chƒÉg\": \"chƒÉng\",\n","    \"ng√†h\": \"ng√†nh\",\n","    \"llac\": \"li√™n l·∫°c\",\n","    \"nk∆∞ng\": \"nh∆∞ng\", \"n·∫Øg\": \"n·∫Øng\", \"t√≠h\": \"t√≠nh\",\n","    \"kho·∫£g\": \"kho·∫£ng\", \"th√≠k\": \"th√≠ch\", \"ngƒëo\": \"ng∆∞·ªùi ƒë√≥\",\n","    \"ngkh√°c\": \"ng∆∞·ªùi kh√°c\", \"th·∫≥g\": \"th·∫≥ng\", \"k·∫£m\": \"c·∫£m\",\n","    \"d√†h\": \"d√†nh\", \"j√∫p\": \"gi√∫p\", \"l·∫∑g\": \"l·∫∑ng\",\n","    \"vƒë√™\": \"v·∫•n ƒë·ªÅ\", \"bb√®\": \"b·∫°n b√®\", \"b√≥g\": \"b√≥ng\",\n","    \"dky\": \"ƒëƒÉng k√Ω\", \"d√≤g\": \"d√≤ng\", \"u·ªëg\": \"u·ªëng\",\n","    \"ty√™u\": \"t√¨nh y√™u\", \"snvv\": \"sinh nh·∫≠t vui v·∫ª\", \"ƒëtho·∫°i\": \"ƒëi·ªán tho·∫°i\",\n","    \"qhe\": \"quan h·ªá\", \"cviec\": \"c√¥ng vi·ªác\", \"t∆∞·ª£g\": \"t∆∞·ª£ng\",\n","    \"q√†\": \"qu√†\", \"thjc\": \"th√≠ch\", \"nh∆∞q\": \"nh∆∞ng\",\n","    \"cƒë·ªùi\": \"cu·ªôc ƒë·ªùi\", \"bth∆∞·ªùng\": \"b√¨nh th∆∞·ªùng\", \"z√†\": \"gi√†\",\n","    \"ƒë√°h\": \"ƒë√°nh\", \"xloi\": \"xin l·ªói\", \"z√°m\": \"d√°m\",\n","    \"qtr·ªçng\": \"quan tr·ªçng\", \"b√¨h\": \"b√¨nh\", \"lzi\": \"l√†m g√¨\",\n","    \"qh·ªá\": \"quan h·ªá\", \"ƒëhbkhn\": \"ƒë·∫°i h·ªçc b√°ch khoa h√† n·ªôi\", \"hajzz\": \"haizz\",\n","    \"k·ªßa\": \"c·ªßa\", \"lz\": \"l√†m g√¨\", \"ƒëhkhtn\": \"ƒë·∫°i h·ªçc khoa h·ªçc t·ª± nhi√™n\",\n","    \"ƒëh\": \"ƒë·∫°i h·ªçc\", \"ƒë√≥g\": \"ƒë√≥ng\", \"cka\": \"cha\",\n","    \"lgi\": \"l√†m g√¨\", \"nv·∫≠y\": \"nh∆∞ v·∫≠y\", \"q·∫£\": \"qu·∫£\",\n","    \"ƒëki·ªán\": \"ƒëi·ªÅu ki·ªán\", \"n√®k\": \"n√®\", \"tlai\": \"t∆∞∆°ng lai\",\n","    \"bsƒ©\": \"b√°c sƒ©\", \"hk√¨\": \"h·ªçc k·ª≥\", \"ƒëcsvn\": \"ƒë·∫£ng c·ªông s·∫£n vi·ªát nam\",\n","    \"vde\": \"v·∫•n ƒë·ªÅ\", \"chta\": \"ch√∫ng ta\", \"√≤y\": \"r·ªìi\",\n","    \"ltinh\": \"linh tinh\", \"ngyeu\": \"ng∆∞·ªùi y√™u\", \"ƒëthoai\": \"ƒëi·ªán tho·∫°i\",\n","    \"snghƒ©\": \"suy nghƒ©\", \"n·∫∑g\": \"n·∫∑ng\", \"h·ªçk\": \"h·ªçc\",\n","    \"d·ª´g\": \"d·ª´ng\", \"hph√∫c\": \"h·∫°nh ph√∫c\", \"hiha\": \"c∆∞·ªùi\",\n","    \"wt√¢m\": \"quan t√¢m\", \"th√≠ck\": \"th√≠ch\", \"chu·ªán\": \"chuy·ªán\",\n","    \"l·∫°h\": \"l·∫°nh\", \"f√¢y\": \"facebook\", \"ntn√†y\": \"nh∆∞ th·∫ø n√†y\",\n","    \"l√∫k\": \"l√∫c\", \"haj\": \"hai\", \"ng√≠a\": \"ngh√≠a\",\n","    \"m·ªõj\": \"m·ªõi\", \"hs∆°\": \"h·ªì s∆°\", \"ctraj\": \"con trai\",\n","    \"trg\": \"tr∆∞·ªùng\", \"ny√™u\": \"ng∆∞·ªùi y√™u\", \"ƒëiiiiiii\": \"ƒëi\",\n","    \"r·ªìii\": \"r·ªìi\", \"cj\": \"ch·ªã\", \"c\": \"c·∫∑c\",\n","    \"kih\": \"kinh\", \"kb\": \"k·∫øt b·∫°n\", \"hixxx\": \"hix\",\n","    \"dth∆∞∆°ng\": \"d·ªÖ th∆∞∆°ng\", \"nhi·ªÅuuu\": \"nhi·ªÅu\", \"ctr√¨nh\": \"ch∆∞∆°ng tr√¨nh\",\n","    \"m√¨nk\": \"m√¨nh\", \"mjh\": \"m√¨nh\", \"ng\": \"ng∆∞·ªùi\",\n","    \"vc\": \"v·ª£ ch·ªìng\", \"uhm\": \"·ª´m\", \"th·ª≥\": \"th√¨\",\n","    \"nyc\": \"ng∆∞·ªùi y√™u c≈©\", \"tks\": \"c·∫£m ∆°n\", \"n√†g\": \"n√†ng\",\n","    \"th√¥ii\": \"th√¥i\", \"ƒëj√™n\": \"ƒëi√™n\", \"bg√°i\": \"b·∫°n g√°i\",\n","    \"v·ªõii\": \"v·ªõi\", \"xink\": \"xinh\", \"hƒë·ªông\": \"h√†nh ƒë·ªông\",\n","    \"ƒëh·ªçc\": \"ƒë·∫°i h·ªçc\", \"mk\": \"m√¨nh\", \"bn\": \"b·∫°n\",\n","    \"thik\": \"th√≠ch\", \"mn\": \"m·ªçi ng∆∞·ªùi\", \"nguoi\": \"ng∆∞·ªùi\",\n","    \"n√≥gn\": \"n√≥ng\", \"hok\": \"kh√¥ng\", \"ko\": \"kh√¥ng\",\n","    \"bik\": \"bi·∫øt\", \"vs\": \"v·ªõi\", \"cx\": \"c≈©ng\",\n","    \"mik\": \"m√¨nh\", \"wtf\": \"c√°i qu√°i g√¨\", \"ƒëc\": \"ƒë∆∞·ª£c\",\n","    \"cmt\": \"b√¨nh lu·∫≠n\", \"ck\": \"ch·ªìng\", \"chk\": \"ch·ªìng\",\n","    \"ngta\": \"ng∆∞·ªùi ta\", \"gƒë\": \"gia ƒë√¨nh\", \"oh\": \"·ªì\",\n","    \"vk\": \"v·ª£\", \"ct√°c\": \"c√¥ng t√°c\", \"sg\": \"s√†i g√≤n\",\n","    \"ae\": \"anh em\", \"ah\": \"√†\", \"·∫°h\": \"·∫°\",\n","    \"r√¨\": \"g√¨\", \"ms\": \"m·ªõi\", \"vn\": \"vi·ªát nam\",\n","    \"nhaa\": \"nha\", \"c≈©g\": \"c≈©ng\", \"ƒëag\": \"ƒëang\",\n","    \"∆°iii\": \"∆°i\", \"hic\": \"hix\", \"ace\": \"anh ch·ªã em\",\n","    \"√†k\": \"√†\", \"uh\": \"·ª´\", \"cmm\": \"con m·∫π m√†y\",\n","    \"cmnr\": \"con m·∫π n√≥ r·ªìi\", \"∆°iiii\": \"∆°i\", \"hnay\": \"h√¥m nay\",\n","    \"ukm\": \"·ª´m\", \"tq\": \"trung qu·ªëc\", \"ctr\": \"ch∆∞∆°ng tr√¨nh\",\n","    \"ƒëii\": \"ƒëi\", \"nch\": \"n√≥i chuy·ªán\", \"trieu\": \"tri·ªáu\",\n","    \"hahah\": \"c∆∞·ªùi\", \"nta\": \"ng∆∞·ªùi ta\", \"ng√®o\": \"ngh√®o\",\n","    \"k√™h\": \"k√™nh\", \"ak\": \"√†\", \"ad\": \"admin\",\n","    \"dme\": \"ƒë·ªãt m·∫π\", \"djt\": \"ƒë·ªãt\", \"add fr\": \"th√™m b·∫°n\",\n","    \"j\": \"g√¨\", \"ny\": \"ng∆∞·ªùi y√™u\", \"dc\": \"ƒë∆∞·ª£c\",\n","    \"qc\": \"qu·∫£ng c√°o\", \"baoh\": \"bao gi·ªù\", \"zui\": \"vui\",\n","    \"z·∫ª\": \"v·∫ª\", \"tym\": \"tim\", \"aye\": \"anh y√™u em\",\n","    \"eya\": \"em y√™u anh\", \"fb\": \"facebook\", \"insta\": \"instagram\",\n","    \"z\": \"v·∫≠y\", \"thich\": \"th√≠ch\", \"vcl\": \"v√£i c·∫£ l·ªìn\",\n","    \"ƒët\": \"ƒëi·ªán tho·∫°i\", \"acc\": \"t√†i kho·∫£n\", \"ccho\": \"con ch√≥\",\n","    \"choei\": \"ch∆°i\", \"l\": \"l·ªìn\", \"loz\": \"l·ªìn\",\n","    \"lozz\": \"l·ªìn\", \"trc\": \"tr∆∞·ªõc\", \"chs\": \"ch·∫≥ng hi·ªÉu sao\",\n","    \"ƒëhs\": \"ƒë√©o hi·ªÉu sao\", \"q√°\": \"qu√°\", \"ntn\": \"nh∆∞ th·∫ø n√†o\",\n","    \"w√°\": \"qu√°\", \"z·∫≠y\": \"v·∫≠y\", \"z√¥\": \"v√¥\",\n","    \"ytb\": \"youtube\", \"vƒë\": \"v√£i ƒë√°i\", \"vchg\": \"v√£i ch∆∞·ªüng\",\n","    \"sml\": \"s·∫•p m·∫∑t l·ªù\", \"mlem\": \"ngon\", \"xl\": \"xin l·ªói\",\n","    \"cmn\": \"con m·∫π n√≥\", \"face\": \"facebook\", \"hjhj\": \"c∆∞·ªùi\",\n","    \"vv\": \"vui v·∫ª\", \"ns\": \"n√≥i\", \"iu\": \"y√™u\",\n","    \"vcƒë\": \"v√£i c·∫£ ƒë√°i\", \"in4\": \"th√¥ng tin\", \"qq\": \"qu·∫ßn qu√®\",\n","    \"sub\": \"theo d√µi\", \"kh\": \"kh√¥ng\", \"z·∫°\": \"v·∫≠y\",\n","    \"oy\": \"r·ªìi\", \"jo\": \"gi·ªù\", \"clmm\": \"c√°i l·ªìn m·∫π m√†y\",\n","    \"clgt\": \"c√°i l·ªìn g√¨ th·∫ø\", \"bsvv\": \"bu·ªïi s√°ng vui v·∫ª\",\n","    \"troai\": \"trai\", \"wa\": \"qu√°\", \"hjx\": \"hix\",\n","    \"e\": \"em\", \"ik\": \"ƒëi\", \"ji\": \"g√¨\",\n","    \"ce\": \"ch·ªã em\", \"lm\": \"l√†m\", \"ƒëz\": \"ƒë·∫πp trai\",\n","    \"sr\": \"xin l·ªói\", \"ib\": \"inbox\", \"hoy\": \"th√¥i\",\n","    \"ƒëbh\": \"ƒë√©o bao gi·ªù\", \"k\": \"kh√¥ng\", \"vd\": \"v√≠ d·ª•\",\n","    \"a\": \"anh\", \"c≈©ng z\": \"c≈©ng v·∫≠y\", \"z l√†\": \"v·∫≠y l√†\",\n","    \"unf\": \"h·ªßy k·∫øt b·∫°n\", \"my fen\": \"b·∫°n t√¥i\", \"fen\": \"b·∫°n\",\n","    \"cty\": \"c√¥ng ty\", \"on lai\": \"online\", \"u hai ba\": \"u23\",\n","    \"ai √¥ si ma\": \"h√†i\", \"k√¥\": \"kh√¥ng\", \"ƒëtqg\": \"ƒë·ªôi tuy·ªÉn qu·ªëc gia\",\n","    \"hqua\": \"h√¥m qua\", \"xog\": \"xong\", \"uk\": \"·ª´\",\n","    \"nho√©\": \"nh√©\", \"biet\": \"bi·∫øt\", \"qu√≠\": \"qu√Ω\",\n","    \"stk\": \"s·ªë t√†i kho·∫£n\", \"hong kong\": \"h·ªìng k√¥ng\", \"ƒë∆∞∆°c\": \"ƒë∆∞·ª£c\",\n","    \"ngh√†nh\": \"ng√†nh\", \"nvqs\": \"nghƒ©a v·ª• qu√¢n s·ª±\", \"ng·ª´oi\": \"ng∆∞·ªùi\",\n","    \"trog\": \"trong\", \"tgian\": \"th·ªùi gian\", \"bi√™t\": \"bi·∫øt\",\n","    \"f·∫£i\": \"ph·∫£i\", \"ngu·ªùi\": \"ng∆∞·ªùi\", \"tƒën\": \"th·∫ø ƒë√©o n√†o\",\n","    \"bth\": \"b√¨nh th∆∞·ªùng\", \"tgdd\": \"th·∫ø gi·ªõi di ƒë·ªông\", \"khg\": \"kh√¥ng\",\n","    \"nh∆∞g\": \"nh∆∞ng\", \"thpt\": \"trung h·ªçc ph·ªï th√¥ng\", \"th·∫±g\": \"th·∫±ng\",\n","    \"ƒëu·ª£c\": \"ƒë∆∞·ª£c\", \"dcu\": \"ƒë·ªãt c·ª•\", \"√†h\": \"√†\",\n","    \"ku\": \"cu\", \"th√Ωm\": \"th√≠m\", \"onl\": \"online\",\n","    \"z√¥\": \"d√¥\", \"z√∫\": \"v√∫\", \"cmnd\": \"ch·ª©ng minh nh√¢n d√¢n\",\n","    \"sƒët\": \"s·ªë ƒëi·ªán tho·∫°i\", \"klq\": \"kh√¥ng li√™n quan\", \"ok\": \"ƒë∆∞·ª£c\",\n","    \"m\": \"m√†y\", \"view\": \"c·∫£nh\", \"now\": \"b√¢y gi·ªù\",\n","    \"set\": \"ƒë·∫∑t\", \"nv\": \"nh√¢n vi√™n\", \"cheese\": \"ph√¥ mai\",\n","    \"t\": \"tao\", \"size\": \"k√≠ch th∆∞·ªõc\", \"decor\": \"trang tr√≠\",\n","    \"nc\": \"n∆∞·ªõc\", \"free\": \"mi·ªÖn ph√≠\", \"h\": \"gi·ªù\",\n","    \"thui\": \"th√¥i\", \"hn\": \"h√† n·ªôi\", \"socola\": \"s√¥ c√¥ la\",\n","    \"bt\": \"b√¨nh th∆∞·ªùng\", \"oke\": \"ƒë∆∞·ª£c\", \"nhg\": \"nh∆∞ng\",\n","    \"recommend\": \"g·ª£i √Ω\", \"shipper\": \"giao h√†ng\", \"best\": \"t·ªët\",\n","    \"check\": \"ki·ªÉm tra\", \"hot\": \"n·ªïi b·∫≠t\", \"full\": \"ƒë·∫ßy\",\n","    \"sale\": \"gi·∫£m gi√°\", \"mix\": \"k·∫øt h·ª£p\", \"ord\": \"ƒë·∫∑t h√†ng\",\n","    \"tui\": \"t√¥i\", \"voucher\": \"m√£ gi·∫£m gi√°\", \"th·ª© n\": \"th·ª© nhi·ªÅu\",\n","    \"note\": \"ghi ch√∫\", \"nice\": \"t·ªët\", \"ƒë\": \"ƒë√©o\",\n","    \"nchung\": \"n√≥i chung\", \"vote\": \"ƒë√°nh gi√°\", \"ncl\": \"n√≥i chung l√†\",\n","    \"good\": \"t·ªët\", \"nh\": \"nh∆∞ng\", \"b\": \"b·∫°n\",\n","    \"nvien\": \"nh√¢n vi√™n\", \"up\": \"ƒëƒÉng\", \"bill\": \"h√≥a ƒë∆°n\",\n","    \"bltm\": \"b√¥ng lan tr·ª©ng mu·ªëi\", \"fact\": \"s·ª± th·∫≠t\", \"cf\": \"c√† ph√™\",\n","    \"l√¥n`\": \"l·ªìn\", \"bthg\": \"b√¨nh th∆∞·ªùng\", \"to·∫πt\": \"tuy·ªát\",\n","    \"thk\": \"th√≠ch\", \"dag\": \"ƒëang\", \"delete\": \"x√≥a\",\n","    \"ss\": \"samsung\", \"xau\": \"x·∫•u\", \"dep\": \"ƒë·∫πp\",\n","    \"ip\": \"iphone\", \"ngoo\": \"ngu\"\n","}\n","\n","# 3. L∆∞u file\n","file_path = f\"{DIR_KEYWORD}/teencode.json\"\n","with open(file_path, 'w', encoding='utf-8') as f:\n","    # indent=4 gi√∫p format ƒë·∫πp (m·ªói d√≤ng 1 c·∫∑p)\n","    # ensure_ascii=False gi√∫p hi·ªÉn th·ªã ti·∫øng Vi·ªát kh√¥ng b·ªã l·ªói \\u...\n","    json.dump(teencode_dict, f, ensure_ascii=False, indent=4)\n","TEENCODE_FILE    = f\"{DIR_KEYWORD}/teencode.json\"\n","print(f\"‚úÖ ƒê√£ l∆∞u file teencode.json th√†nh c√¥ng t·∫°i: {file_path}\")"],"metadata":{"id":"yJcSf6tEUiIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 3: IMPORT TH∆Ø VI·ªÜN & KI·ªÇM TRA H·ªÜ TH·ªêNG\n","# ======================================================\n","!pip install pyngrok flask\n","\n","# 1. C√°c th∆∞ vi·ªán x·ª≠ l√Ω d·ªØ li·ªáu c∆° b·∫£n\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import re\n","\n","# 2. C√°c th∆∞ vi·ªán Deep Learning (TensorFlow/Keras)\n","# (Import lu√¥n ·ªü ƒë√¢y ƒë·ªÉ Cell 6 kh√¥ng b·ªã l·ªói)\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, SpatialDropout1D\n","from tensorflow.keras.models import load_model\n","from pyngrok import ngrok\n","from flask import Flask, request, render_template_string\n","\n","# 3. C·∫•u h√¨nh giao di·ªán bi·ªÉu ƒë·ªì\n","sns.set(style=\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (12, 6)\n","\n","# 4. Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa c√°c file quan tr·ªçng\n","# (S·ª≠ d·ª•ng c√°c bi·∫øn ƒë∆∞·ªùng d·∫´n ƒë√£ ƒë·ªãnh nghƒ©a ·ªü Cell 2)\n","print(f\"üìÇ ƒêang ki·ªÉm tra d·ªØ li·ªáu t·∫°i: {BASE_PATH}\")\n","\n","files_to_check = {\n","    \"Dataset CSV\": DATASET_FILE,\n","    \"Keywords JSON\": KEYWORDS_FILE,\n","    \"Teencode JSON\": TEENCODE_FILE,\n","    \"Embedding Vector\": EMBEDDING_FILE,\n","    \"Ngrok Token\": NGROK_TOKEN_FILE\n","}\n","\n","all_good = True\n","for name, path in files_to_check.items():\n","    if os.path.exists(path):\n","        print(f\"  ‚úÖ {name}: OK\")\n","    else:\n","        print(f\"  ‚ùå {name}: KH√îNG T√åM TH·∫§Y (ƒê∆∞·ªùng d·∫´n: {path})\")\n","        all_good = False\n","\n","if all_good:\n","    print(\"\\n=> T·∫•t c·∫£ file ƒë√£ s·∫µn s√†ng!\")\n","else:\n","    print(\"\\n=> ‚ö†Ô∏è C√≥ file b·ªã thi·∫øu, vui l√≤ng ki·ªÉm tra l·∫°i Google Drive.\")"],"metadata":{"id":"d6rwKRC9donD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 4: LOAD TEENCODE & H√ÄM L√ÄM S·∫†CH TEXT\n","# ======================================================\n","\n","# 1. Load Teencode t·ª´ file JSON (Code c≈© b·ªã sai ·ªü ƒë√¢y)\n","TEENCODE_DICT = {}\n","if os.path.exists(TEENCODE_FILE):\n","    try:\n","        with open(TEENCODE_FILE, 'r', encoding='utf-8') as f:\n","            TEENCODE_DICT = json.load(f)\n","        print(f\"‚úÖ ƒê√£ load th√†nh c√¥ng {len(TEENCODE_DICT)} t·ª´ teencode.\")\n","    except Exception as e:\n","        print(f\"‚ùå L·ªói ƒë·ªçc file JSON: {e}\")\n","else:\n","    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file Teencode JSON.\")\n","\n","# 2. ƒê·ªãnh nghƒ©a Emoji\n","EMOJI_DICT = {\n","    r\"(:|;|=)+[ ]*(\\)|3|\\])+\": \" c∆∞·ªùi \",\n","    r\"(:|;|=)+[ ]*(\\(|\\[)+\": \" bu·ªìn \",\n","    r\"(<)+[ ]*(3)+\": \" tim \",\n","    r\"(:|;|=)+[ ]*(v|V)+\": \" pacman \"\n","}\n","\n","# 3. H√†m l√†m s·∫°ch vƒÉn b·∫£n chu·∫©n\n","def clean_text(text):\n","    if not isinstance(text, str): return str(text)\n","    text = text.lower()\n","\n","    # R√∫t g·ªçn k√Ω t·ª± l·∫∑p (vd: ƒë·∫πpppp -> ƒë·∫πp)\n","    text = re.sub(r'([a-zƒë])\\1{2,}', r'\\1', text)\n","\n","    # Thay th·∫ø Emoji\n","    for p, m in EMOJI_DICT.items():\n","        text = re.sub(p, m, text)\n","\n","    # Thay th·∫ø Teencode (D√πng Dictionary ƒë√£ load)\n","    words = text.split()\n","    fixed_words = []\n","    for w in words:\n","        # X·ª≠ l√Ω d·∫•u c√¢u d√≠nh v√†o t·ª´ (vd: \"abc,\" -> \"abc\")\n","        w_clean = re.sub(r'[^\\w]', '', w)\n","        if w_clean in TEENCODE_DICT:\n","            fixed_words.append(TEENCODE_DICT[w_clean])\n","        else:\n","            fixed_words.append(w)\n","\n","    text = \" \".join(fixed_words)\n","\n","    # X√≥a URL v√† k√Ω t·ª± ƒë·∫∑c bi·ªát\n","    text = re.sub(r'http\\S+', '', text)\n","    text = re.sub(r'[^\\w\\s]', ' ', text)\n","\n","    return re.sub(r'\\s+', ' ', text).strip()"],"metadata":{"id":"RNtDr4UueWwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 5: PH√ÇN T√çCH, TR·ª∞C QUAN H√ìA & NH·∫¨N X√âT\n","# ======================================================\n","\n","# 1. ƒê·ªçc d·ªØ li·ªáu\n","df = pd.read_csv(DATASET_FILE)\n","\n","# 2. X·ª≠ l√Ω s·ªë li·ªáu\n","df['word_count'] = df['free_text'].apply(lambda x: len(str(x).split()))\n","\n","# --- S·ª¨A ƒê·ªîI: CH·ªà L·∫§Y PH·∫¶N NGUY√äN (INT) ---\n","avg_length = int(df['word_count'].mean())\n","\n","# Map nh√£n v√† S·∫Øp x·∫øp\n","label_map = {0: '0 - S·∫°ch', 1: '1 - Offensive', 2: '2 - Hate'}\n","df['label_name'] = df['label_id'].map(label_map)\n","order_list = ['0 - S·∫°ch', '1 - Offensive', '2 - Hate']\n","\n","# ƒê·∫øm s·ªë l∆∞·ª£ng\n","label_counts = df['label_id'].value_counts().sort_index()\n","\n","# 3. LOGIC T·ª∞ ƒê·ªòNG NH·∫¨N X√âT\n","# --- C√¢n b·∫±ng d·ªØ li·ªáu ---\n","max_c = label_counts.max()\n","min_c = label_counts.min()\n","ratio = max_c / min_c if min_c > 0 else 0\n","\n","balance_comment = \"\"\n","if ratio < 1.5:\n","    balance_comment = \"‚úÖ D·ªØ li·ªáu KH√Å C√ÇN B·∫∞NG. T·ªët cho vi·ªác hu·∫•n luy·ªán.\"\n","elif ratio < 3:\n","    balance_comment = \"‚ö†Ô∏è D·ªØ li·ªáu H∆†I L·ªÜCH (Imbalanced). Model c√≥ th·ªÉ thi√™n v·ªã nh√£n nhi·ªÅu h∆°n.\"\n","else:\n","    balance_comment = \"‚ùå D·ªØ li·ªáu M·∫§T C√ÇN B·∫∞NG NGHI√äM TR·ªåNG. C·∫ßn c√¢n nh·∫Øc k·ªπ thu·∫≠t Oversampling.\"\n","\n","# --- ƒê·ªô d√†i c√¢u ---\n","len_comment = \"\"\n","if avg_length < 5:\n","    len_comment = \"C√¢u QU√Å NG·∫ÆN. C√≥ th·ªÉ thi·∫øu ng·ªØ c·∫£nh.\"\n","elif 5 <= avg_length <= 20:\n","    len_comment = \"‚úÖ ƒê·ªô d√†i PH√ô H·ª¢P v·ªõi ƒë·∫∑c th√π b√¨nh lu·∫≠n MXH.\"\n","else:\n","    len_comment = \"C√¢u KH√Å D√ÄI so v·ªõi b√¨nh lu·∫≠n th√¥ng th∆∞·ªùng.\"\n","\n","# 4. In th√¥ng tin\n","print(f\"üìä T·ªîNG QUAN DATASET:\")\n","print(f\"- T·ªïng s·ªë c√¢u: {len(df):,}\")\n","print(f\"- ƒê·ªô d√†i trung b√¨nh: ~{avg_length} t·ª´/c√¢u\") # ƒê√£ hi·ªÉn th·ªã s·ªë nguy√™n\n","print(\"-\" * 50)\n","print(f\"NH·∫¨N X√âT:\")\n","print(f\"1. {balance_comment}\")\n","print(f\"2. {len_comment}\")\n","print(\"-\" * 50)\n","\n","# 5. V·∫Ω bi·ªÉu ƒë·ªì\n","fig = plt.figure(figsize=(15, 10))\n","grid = plt.GridSpec(2, 2, wspace=0.3, hspace=0.3)\n","\n","# --- Bi·ªÉu ƒë·ªì 1: C·ªôt ---\n","ax1 = fig.add_subplot(grid[0, 0])\n","sns.countplot(x='label_name', hue='label_name', data=df, order=order_list, palette='viridis', legend=False, ax=ax1)\n","\n","ax1.set_title('S·ªë l∆∞·ª£ng c√¢u theo nh√£n')\n","ax1.set_xlabel('')\n","ax1.set_ylabel('S·ªë l∆∞·ª£ng')\n","for p in ax1.patches:\n","    if p.get_height() > 0:\n","        ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n","                     ha='center', va='bottom', fontsize=10, fontweight='bold')\n","\n","# --- Bi·ªÉu ƒë·ªì 2: Tr√≤n ---\n","ax2 = fig.add_subplot(grid[0, 1])\n","colors = sns.color_palette('viridis', 3)\n","ax2.pie(label_counts, labels=[label_map[i] for i in label_counts.index],\n","        autopct='%1.1f%%', startangle=140, colors=colors, explode=(0.05, 0.05, 0.05))\n","ax2.set_title('T·ª∑ l·ªá ph√¢n b·ªë (%)')\n","\n","# --- Bi·ªÉu ƒë·ªì 3: Histogram ---\n","ax3 = fig.add_subplot(grid[1, :])\n","sns.histplot(df['word_count'], bins=50, kde=True, color='royalblue', ax=ax3)\n","ax3.axvline(avg_length, color='red', linestyle='dashed', linewidth=2, label=f'TB: ~{avg_length} t·ª´')\n","ax3.set_title('Ph√¢n b·ªë ƒë·ªô d√†i c√¢u')\n","ax3.legend()\n","\n","plt.show()"],"metadata":{"id":"4SohCqiahVla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 6A: PREPROCESSING & SPLIT DATA\n","# ======================================================\n","\n","# 1. √Åp d·ª•ng l√†m s·∫°ch d·ªØ li·ªáu\n","df['clean_text'] = df['free_text'].apply(lambda x: clean_text(str(x)))\n","\n","# 2. Tokenizer\n","tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ')\n","tokenizer.fit_on_texts(df['clean_text']) # Fit tr√™n c·ªôt ƒë√£ l√†m s·∫°ch\n","word_index = tokenizer.word_index\n","print(f\"   => T√¨m th·∫•y {len(word_index)} t·ª´ ƒë·ªôc nh·∫•t trong t·ª´ ƒëi·ªÉn.\")\n","\n","# 3. Chuy·ªÉn vƒÉn b·∫£n sang chu·ªói s·ªë (Sequence) & Padding\n","X = tokenizer.texts_to_sequences(df['clean_text'])\n","X = pad_sequences(X, maxlen=MAX_LEN)\n","\n","# 4. Label Encoding (One-hot)\n","y = to_categorical(df['label_id'])\n","\n","# 5. Chia t·∫≠p Train/Test (80% Train - 20% Test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"‚úÖ D·ªØ li·ªáu s·∫µn s√†ng!\")\n","print(f\"   - Shape X_train: {X_train.shape}\")\n","print(f\"   - Shape y_train: {y_train.shape}\")"],"metadata":{"id":"nEoMn_szhbVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 6B: LOAD PRE-TRAINED EMBEDDING\n","# ======================================================\n","\n","embedding_matrix = np.zeros((len(word_index) + 1, EMBED_DIM))\n","hit = 0\n","\n","if os.path.exists(EMBEDDING_FILE):\n","    with open(EMBEDDING_FILE, 'r', encoding='utf-8') as f:\n","        # Ki·ªÉm tra d√≤ng ƒë·∫ßu ti√™n (Header c·ªßa FastText)\n","        first_line = f.readline()\n","        if len(first_line.split()) > 2:\n","             f.seek(0) # N·∫øu kh√¥ng ph·∫£i header (ch·ª©a 2 s·ªë) th√¨ quay l·∫°i ƒë·∫ßu\n","\n","        for line in f:\n","            values = line.rstrip().rsplit(' ') # rsplit an to√†n h∆°n cho t·ª´ c√≥ d·∫•u c√°ch\n","            word = values[0]\n","            if word in word_index:\n","                try:\n","                    coefs = np.asarray(values[1:], dtype='float32')\n","                    if coefs.shape[0] == EMBED_DIM:\n","                        embedding_matrix[word_index[word]] = coefs\n","                        hit += 1\n","                except:\n","                    continue\n","\n","    # T√≠nh ƒë·ªô ph·ªß\n","    coverage = (hit / len(word_index)) * 100 if len(word_index) > 0 else 0\n","    print(f\"- S·ªë t·ª´ t√¨m th·∫•y (Hits): {hit}\")\n","    print(f\"- T·ªâ l·ªá ph·ªß (Coverage): {coverage:.2f}%\")\n","else:\n","    print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file Embedding t·∫°i {EMBEDDING_FILE}. Model s·∫Ω h·ªçc Embedding t·ª´ ƒë·∫ßu.\")"],"metadata":{"id":"_PvQCtL4Dtxs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 6C: BUILD MODEL, TRAIN & SAVE (ƒê√É FIX WARNING)\n","# ======================================================\n","\n","# 1. X√¢y d·ª±ng ki·∫øn tr√∫c Model\n","model = Sequential()\n","\n","# Layer 1: Embedding\n","model.add(Embedding(input_dim=len(word_index) + 1,\n","                    output_dim=EMBED_DIM,\n","                    weights=[embedding_matrix] if hit > 0 else None,\n","                    trainable=False)) # False = Kh√¥ng train l·∫°i vector c√≥ s·∫µn\n","\n","# Layer 2: Spatial Dropout\n","model.add(SpatialDropout1D(0.3))\n","\n","# Layer 3: Bidirectional LSTM\n","model.add(Bidirectional(LSTM(128, return_sequences=True)))\n","model.add(Bidirectional(LSTM(64)))\n","\n","# Layer 4: Dense\n","model.add(Dense(64, activation='relu'))\n","\n","# Layer 5: Output\n","model.add(Dense(3, activation='softmax'))\n","\n","# 2. Compile Model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Build model v·ªõi input shape c·ª• th·ªÉ ƒë·ªÉ hi·ªÉn th·ªã summary\n","model.build(input_shape=(None, MAX_LEN))\n","model.summary()\n","\n","# 3. Training\n","history = model.fit(X_train, y_train,\n","                    epochs=10,\n","                    batch_size=64,\n","                    validation_data=(X_test, y_test),\n","                    verbose=1)\n","\n","# 4. L∆∞u Model & Tokenizer\n","model.save(MODEL_FILE)\n","with open(TOKENIZER_FILE, 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","print(f\"\\n‚úÖ ƒê√£ l∆∞u Model t·∫°i: {MODEL_FILE}\")\n","print(f\"‚úÖ ƒê√£ l∆∞u Tokenizer t·∫°i: {TOKENIZER_FILE}\")"],"metadata":{"id":"iljuWbnjDxDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL A: C·∫¨P NH·∫¨T FILE KEYWORDS.JSON\n","# ======================================================\n","valid_keywords = {\n","  \"Ph√¢n bi·ªát v√πng mi·ªÅn\": [\n","    \"b·∫Øc k·ª≥\", \"nam k·ª≥\", \"trung k·ª≥\", \"parky\", \"namiki\", \"hoa thanh que\", \"nh√† qu√™\", \"t·ªôc\", \"m·ªçi mi√™n\", \"bake\", \"narke\"\n","  ],\n","  \"Ch√≠nh tr·ªã / Nh·∫°y c·∫£m\": [\n","    \"ph·∫£n ƒë·ªông\", \"c·ªông s·∫£n\", \"ch·∫ø ƒë·ªô\", \"ƒëu c√†ng\", \"ba que\", \"tham nh≈©ng\", \"d√¢n ch·ªß cu·ªôi\", \"b√≤ ƒë·ªè\", \"c√°ch m·∫°ng m√†u\"\n","  ],\n","  \"K√≠ch ƒë·ªông / B·∫°o l·ª±c\": [\n","     \"b·∫Øn b·ªè\", \"gi·∫øt\", \"ch√©m\", \"t·ª≠ h√¨nh\", \"ƒë√°nh ch·∫øt\", \"th·ªß ti√™u\", \"x·ª≠ b·∫Øn\", \"treo c·ªï\", \"bƒÉm v·∫±m\", \"thanh tr·ª´ng\"\n","  ],\n","  \"C·ªï x√∫y / X√∫i gi·ª•c\": {\n","    \"T·ª´ kh√≥a c·ªë ƒë·ªãnh\": [\n","        \"t·ª± t·ª≠ ƒëi\", \"t·ª± s√°t ƒëi\", \"nh·∫£y c·∫ßu ƒëi\", \"nh·∫£y l·∫ßu ƒëi\", \"reset ki·∫øp sau\"\n","    ],\n","    \"Bi·∫øn th·ªÉ Regex (Ng·∫Øn g·ªçn)\": [\n","        r\"(m√†y|m|b·∫°n|con|th·∫±ng|n√≥)[ ]*ch·∫øt[ ]*(ƒëi|ƒë√™|li·ªÅn|ngay)\",\n","        r\"ch·∫øt[ ]*(ƒëi|ƒë√™|li·ªÅn|ngay|lu√¥n)\",\n","        r\"reset[ ]*(game|server)[ ]*ƒëi\"\n","    ]\n","  },\n","  \"X√∫c ph·∫°m / T·ª•c tƒ©u\": {\n","    \"T·ª´ kh√≥a c·ªë ƒë·ªãnh\": [\n","      \"ngu si\", \"ngu h·ªçc\", \"ngu d·ªët\", \"√≥c ch√≥\", \"ƒë·ªì ch√≥\", \"ch√≥ ƒë·∫ª\", \"ch√≥ ch·∫øt\",\n","      \"s√∫c v·∫≠t\", \"c√∫t x√©o\", \"m·∫π m√†y\", \"c·∫∑c\", \"l·ªìn\", \"ƒë√©o\", \"ƒë·ª•\",\n","      \"bu·ªìi\", \"cak\", \"kak\", \"ƒëƒ©\", \"ƒëi·∫øm\", \"ph√≤\", \"bitch\", \"cave\",\n","      \"dcmm\", \"ƒëcmm\", \"vcl\"\n","    ],\n","    \"Bi·∫øn th·ªÉ Regex (Ng·∫Øn g·ªçn)\": [\n","      r\"\\bc[.,\\s]*m[.,\\s]*(m|n)\\b\",           # cmm\n","      r\"\\b(ƒë|d)[.,\\s]*(c|k)?[.,\\s]*m+\\b\",     # dcm\n","      r\"\\bv[.,\\s]*(l|c|k)+\\b\",                # vcl\n","      r\"\\b(c)?[.,\\s]*m[.,\\s]*m[.,\\s]*b\\b\",    # cmmb\n","      r\"\\bb[.,\\s]*m[.,\\s]*g\\b\",               # bmg\n","      r\"(ƒë|d)[.,\\s]*√©[.,\\s]*o\",               # ƒë√©o\n","      r\"c[.,\\s]*·∫∑[.,\\s]*c\"                    # c·∫∑c\n","    ]\n","  },\n","  \"Mi·ªát th·ªã ngo·∫°i h√¨nh (Body Shaming)\": [\n","      \"b√©o nh∆∞ l·ª£n\", \"m·∫≠p nh∆∞ heo\", \"con heo m·∫≠p\", \"x·∫•u ƒëau x·∫•u ƒë·ªõn\",\n","      \"m·∫∑t l·ªìn\", \"m√†n h√¨nh ph·∫≥ng\", \"hai l∆∞ng\"\n","  ],\n","  \"Ph√¢n bi·ªát gi·ªõi t√≠nh\": [\n","      \"ƒë·ªì ƒë√†n b√†\", \"√≥c ƒë√†n b√†\", \"t√≠nh ƒë√†n b√†\", \"th·ª© ƒë√†n b√†\", \"m·∫•y con d·∫©m\",\n","      \"v·ªÅ r·ª≠a b√°t\", \"v·ªÅ h·∫ßu ch·ªìng\", \"m√°y ƒë·∫ª\"\n","  ],\n","  \"Ph√¢n bi·ªát t√¥n gi√°o\": [\n","      \"th·ª£ tu\", \"s∆∞ h·ªï mang\", \"t√† ƒë·∫°o\", \"bu√¥n th·∫ßn b√°n th√°nh\", \"con chi√™n gh·∫ª\"\n","  ]\n","}\n","\n","positive_keywords = [\n","    \"ƒë√°ng y√™u\", \"d·ªÖ th∆∞∆°ng\", \"cute\", \"xinh g√°i\", \"ƒë·∫πp trai\", \"ngoan\",\n","    \"t·ªët b·ª•ng\", \"hi·ªÅn l√†nh\", \"tuy·ªát v·ªùi\", \"xu·∫•t s·∫Øc\", \"th√¥ng minh\",\n","    \"y√™u th·∫ø\", \"c∆∞ng x·ªâu\", \"c∆∞ng th·∫ø\", \"gi·ªèi qu√°\", \"th∆∞∆°ng l·∫Øm\",\n","    \"xinh th·∫ø\", \"ƒë·∫πp th·∫ø\", \"iu th·∫ø\", \"respect\", \"ng∆∞·ª°ng m·ªô\"\n","]\n","\n","try:\n","    with open(KEYWORDS_FILE, 'w', encoding='utf-8') as f:\n","        json.dump(valid_keywords, f, ensure_ascii=False, indent=2)\n","\n","    with open(WHITELIST_FILE, 'w', encoding='utf-8') as f:\n","        json.dump(positive_keywords, f, ensure_ascii=False, indent=2)\n","\n","except Exception as e:\n","    print(f\"‚ùå L·ªói: {e}\")"],"metadata":{"id":"QmuSrhEVnCx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======================================================\n","# CELL 7: WEB APP (FULL LOGIC)\n","# ======================================================\n","# 1. C·∫•u h√¨nh & Load file\n","# Token c·ªßa b·∫°n (C√≥ th·ªÉ thay th·∫ø n·∫øu c·∫ßn)\n","NGROK_TOKEN = \"PASTE_YOUR_TOKEN_HERE\"\n","ngrok.set_auth_token(NGROK_TOKEN)\n","\n","# Ng·∫Øt c√°c k·∫øt n·ªëi c≈© ƒë·ªÉ tr√°nh l·ªói\n","ngrok.kill()\n","\n","try:\n","    model = load_model(MODEL_FILE)\n","    with open(TOKENIZER_FILE, 'rb') as h: tokenizer = pickle.load(h)\n","    with open(KEYWORDS_FILE, 'r', encoding='utf-8') as f: KEYWORDS = json.load(f)\n","    with open(WHITELIST_FILE, 'r', encoding='utf-8') as f: WHITELIST = json.load(f)\n","except Exception as e:\n","    print(f\"‚ùå L·ªói load file: {e}\")\n","\n","# 2. H√†m Check Whitelist (Ng·ªØ c·∫£nh t√≠ch c·ª±c)\n","def check_whitelist(text):\n","    for word in WHITELIST:\n","        if word in text:\n","            return True\n","    return False\n","\n","# 3. H√†m Check T·ª´ kh√≥a Vi ph·∫°m\n","def check_keywords_app(text):\n","    # L∆∞u √Ω: H√†m clean_text ph·∫£i ƒë∆∞·ª£c define ·ªü Cell 4\n","    norm = clean_text(text)\n","    detected_categories = []\n","\n","    for category, content in KEYWORDS.items():\n","        is_violated = False\n","        if isinstance(content, list):\n","            for word in content:\n","                if word in norm: is_violated = True; break\n","        elif isinstance(content, dict):\n","            if \"T·ª´ kh√≥a c·ªë ƒë·ªãnh\" in content:\n","                for word in content[\"T·ª´ kh√≥a c·ªë ƒë·ªãnh\"]:\n","                    if word in norm: is_violated = True; break\n","            if not is_violated and \"Bi·∫øn th·ªÉ Regex (Ng·∫Øn g·ªçn)\" in content:\n","                for pattern in content[\"Bi·∫øn th·ªÉ Regex (Ng·∫Øn g·ªçn)\"]:\n","                    try:\n","                        if re.search(pattern, norm): is_violated = True; break\n","                    except: continue\n","\n","        if is_violated: detected_categories.append(category)\n","    return list(set(detected_categories)), norm\n","\n","# 4. Flask App\n","app = Flask(__name__)\n","\n","@app.route('/', methods=['GET', 'POST'])\n","def index():\n","    res, status, debug, original = \"\", \"\", \"\", \"\"\n","\n","    if request.method == 'POST':\n","        original = request.form['txt']\n","\n","        # B1: Check t·ª´ kh√≥a\n","        violation_list, cleaned = check_keywords_app(original)\n","\n","        # B2: Check Whitelist (Ng·ªØ c·∫£nh t√≠ch c·ª±c)\n","        is_positive = check_whitelist(cleaned)\n","\n","        # B3: Check AI\n","        seq = tokenizer.texts_to_sequences([cleaned])\n","        pad = pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n","        pred_label = np.argmax(model.predict(pad, verbose=0))\n","\n","        # --- LOGIC RA QUY·∫æT ƒê·ªäNH ---\n","\n","        # C√°c l·ªói nghi√™m tr·ªçng (Kh√¥ng th·ªÉ tha th·ª© d√π c√≥ khen)\n","        CRITICAL_ERRORS = [\"Ch√≠nh tr·ªã / Nh·∫°y c·∫£m\", \"K√≠ch ƒë·ªông / B·∫°o l·ª±c\", \"C·ªï x√∫y / X√∫i gi·ª•c\"]\n","        has_critical = any(err in violation_list for err in CRITICAL_ERRORS)\n","\n","        # Case 1: C√≥ t·ª´ khen V√Ä kh√¥ng d√≠nh l·ªói nghi√™m tr·ªçng -> THA B·ªîNG\n","        if is_positive and not has_critical:\n","            status = \"SAFE\"\n","            res = \"‚úÖ N·ªòI DUNG S·∫†CH (Ng·ªØ c·∫£nh t√≠ch c·ª±c)\"\n","            # V√≠ d·ª•: \"M√†y ngu gh√™ nh∆∞ng m√† cute\" -> S·∫Ω ƒë∆∞·ª£c tha v√¨ c√≥ 'cute' v√† 'ngu' kh√¥ng ph·∫£i critical.\n","\n","        # Case 2: Vi ph·∫°m t·ª´ kh√≥a\n","        elif violation_list:\n","            status = \"DANGER\"\n","            res = f\"üö´ VI PH·∫†M: {', '.join(violation_list)}\"\n","\n","        # Case 3: AI b√°o Hate Speech (2)\n","        elif pred_label == 2:\n","            status = \"DANGER\"; res = \"üö´ PH√ÅT HI·ªÜN: NG√îN T·ª™ TH√ô GH√âT\"\n","\n","        # Case 4: AI b√°o Offensive (1)\n","        elif pred_label == 1:\n","            status = \"WARNING\"; res = \"‚ö†Ô∏è C·∫¢NH B√ÅO: N·ªòI DUNG TI√äU C·ª∞C\"\n","\n","        # Case 5: S·∫°ch\n","        else:\n","            status = \"SAFE\"; res = \"‚úÖ N·ªòI DUNG S·∫†CH\"\n","\n","        debug = cleaned\n","\n","    html = \"\"\"\n","    <!DOCTYPE html>\n","    <html lang=\"vi\">\n","    <head>\n","        <meta charset=\"utf-8\">\n","        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n","        <title>Hate Speech Detector</title>\n","        <style>\n","            body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f0f2f5; display: flex; justify-content: center; align-items: center; min-height: 100vh; margin: 0; }\n","            .container { background: white; padding: 40px; border-radius: 20px; box-shadow: 0 15px 35px rgba(0,0,0,0.1); width: 100%; max-width: 550px; }\n","            h2 { text-align: center; color: #1a1a1a; margin-bottom: 25px; font-weight: 700; }\n","            textarea { width: 100%; height: 120px; padding: 15px; border: 2px solid #e1e4e8; border-radius: 12px; font-size: 16px; resize: none; box-sizing: border-box; font-family: inherit; }\n","            textarea:focus { border-color: #3b82f6; outline: none; }\n","            button { width: 100%; padding: 15px; background: #3b82f6; color: white; border: none; border-radius: 12px; font-size: 16px; font-weight: 600; cursor: pointer; margin-top: 20px; transition: 0.2s; }\n","            button:hover { background: #2563eb; transform: translateY(-1px); }\n","\n","            .result-box { margin-top: 30px; padding: 20px; border-radius: 12px; text-align: center; animation: fadeIn 0.5s; }\n","            .SAFE { background: #d1fae5; color: #065f46; border: 1px solid #a7f3d0; }\n","            .WARNING { background: #ffedd5; color: #9a3412; border: 1px solid #fed7aa; }\n","            .DANGER { background: #fee2e2; color: #991b1b; border: 1px solid #fecaca; }\n","            .result-text { font-size: 18px; font-weight: bold; margin-bottom: 5px; }\n","            .debug-text { font-size: 12px; color: #6b7280; margin-top: 10px; font-style: italic; }\n","            @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }\n","        </style>\n","    </head>\n","    <body>\n","        <div class=\"container\">\n","            <h2>üõ°Ô∏è Ki·ªÉm duy·ªát b√¨nh lu·∫≠n</h2>\n","            <form method=\"post\">\n","                <textarea name=\"txt\" placeholder=\"Nh·∫≠p b√¨nh lu·∫≠n c·∫ßn ki·ªÉm tra...\">{{original}}</textarea>\n","                <button type=\"submit\">KI·ªÇM TRA NGAY</button>\n","            </form>\n","            {% if res %}\n","                <div class=\"result-box {{status}}\">\n","                    <div class=\"result-text\">{{res}}</div>\n","                    <div class=\"debug-text\">AI ƒë√£ x·ª≠ l√Ω: \"{{debug}}\"</div>\n","                </div>\n","            {% endif %}\n","        </div>\n","    </body>\n","    </html>\n","    \"\"\"\n","    return render_template_string(html, res=res, status=status, debug=debug, original=original)\n","\n","# M·ªü c·ªïng 5000\n","public_url = ngrok.connect(5000).public_url\n","print(f\"üöÄ CLICK V√ÄO ƒê√ÇY ƒê·ªÇ M·ªû APP: {public_url}\")\n","app.run(port=5000)"],"metadata":{"id":"COIEJi6Y3X9l"},"execution_count":null,"outputs":[]}]}